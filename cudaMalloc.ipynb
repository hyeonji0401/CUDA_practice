{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMfa5RC1D4aPuMSK/RW2CLB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonji0401/CUDA_practice/blob/main/cudaMalloc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 CUDA 프로그램의 구조 및 흐름\n",
        "호스트 코드가 반드시 필요한 이유\n",
        "\n",
        "> CPU가 운영체제와 같은 컴퓨터 시스템의 기본 연산 장치이며, GPU와 같은 다른 연산 장치를 사용하기 위해서는 호스트 코드에서 커널을 호출해야 하기 때문임\n",
        "\n",
        "* CPU와 GPU는 서로 독립된 장치로 사용하는 메모리 영역이 다름\n",
        "* GPU는 디바이스 메모리를 사용하지만 모든 데이터는 기본적으로 호스트 메모리에 저장되어있음\n",
        "\n",
        "=> GPU를 이용해서 데이터를 처리하기 위해서는 호스트 메모리에 있는 데이터를 디바이스 메모리로 복사해주어야함\n",
        "\n",
        "<CUDA 프로그램 흐름>\n",
        "1. 호스트 -> 디바이스 데이터 복사(GPU에서 처리할 데이터)\n",
        "2. GPU연산\n",
        "3. 디바이스 -> 호스트 데이터 복사(연산 결과 데이터)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "89V3aBSfO-DX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 CUDA 기초 메모리 API\n",
        "\n",
        "**1. 디바이스 메모리 공간 할당 및 초기화**\n",
        "> 디바이스 메모리로 데이터를 복사하기 위해서는 메모리에 사용할 공간을 할당받아야함\n",
        "\n",
        "> 이는 C언어 malloc()함수와 동일함\n",
        "\n",
        "> 차이점은 C언어는 호스트 공간의 메모리를 할당하는 것이고 cudaMalloc()은 디바이스 메모리 공간을 할당받는 것임\n",
        "\n",
        "**디바이스 메모리 할당**\n",
        "* cudaMalloc()\n",
        "\n",
        "함수 원형\n",
        "\n",
        "\n",
        "```\n",
        "cudaError_t cudaMalloc(void **ptr, size_t size)\n",
        "```\n",
        "1. void **ptr\n",
        "- 디바이스 메모리 공간의 시작 주소를 담을 포인터 변수의 주소\n",
        "\n",
        "2. size_t size\n",
        "- 할당할 공간의 크기(byte 단위)\n",
        "\n",
        "3. 반환형\n",
        "- cudaError_t 열거형\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "krZ_OYoKQcPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "    int *dDataPtr;\n",
        "    cudaMalloc(&dDataPtr, sizeof(int)*32);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLkQnIahRp_S",
        "outputId": "c407ce84-3b3e-4e07-c996-0f3f05a39c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 코드는 디바이스 메모리 공간에 int형 데이터 32개를 담을 공간을 할당하는 예시임\n",
        "\n",
        "위에서 설명했던 것과 같이 &dDatePtr가 할당된 메모리 공간의 시작주소가 저장되는 포인터 변수가 되는 것\n",
        "\n",
        "* 주의할 점 : dDatePtr이 가리키는 주소는 디바이스 메모리 주소이므로 호스트 코드에서 직접 접근할 수 없다\n",
        "\n",
        "그래서 만약\n"
      ],
      "metadata": {
        "id": "_KJXeHvgShfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "    int *dDataPtr;\n",
        "    cudaMalloc(&dDataPtr, sizeof(int)*32);\n",
        "    printf(\"%d\", dDataPtr[0]);\n",
        "    cudaFree(dDataPtr);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAQrl_oFTTql",
        "outputId": "59d262ca-9f02-4231-fe95-f9c0a5163a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이와 같이 데이터에 접근하면 실행 오류가 발생함\n",
        "\n",
        "**printf()는 CPU에서 작동하는 코드이기 때문임**\n",
        "\n",
        "\n",
        "\n",
        "> CUDA 프로그램에서는 호스트 메모리 영역을 사용한느 변수와 디바이스 메모리 영역을 사용하는 변수를 구분하기 위해 일반적으로 디바이스 메모리 영역을 사용하는 변수의 이름 앞에 디바이스를 뜻하는 d를 붙여줌\n",
        "\n",
        "* cudaFree()는 할당된 메모리를 해제하는 함수"
      ],
      "metadata": {
        "id": "H8EoydjKUFVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**디바이스 메모리 해제**\n",
        "\n",
        "* cudaFree()\n",
        "\n",
        "함수 원형\n",
        "\n",
        "\n",
        "```\n",
        "cudaError_t cudaFree(void* ptr)\n",
        "```\n",
        "1.void *ptr\n",
        "- 해제할 메모리 공간을 가리키는 포인터 변수\n",
        "\n",
        "2. 반환형\n",
        "- cudaError_t 열거형"
      ],
      "metadata": {
        "id": "3ALm6QRUmsqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**디바이스 메모리 초기화**\n",
        "\n",
        "- cudaMemset()\n",
        "\n",
        "\n",
        "> cudaMalloc()을 통해 메모리 공간을 할당받으면 해당 메모리 공간에 남아있던 쓰레기 값이 그대로 남아있으므로 초기화 해줘야함\n",
        "\n",
        "함수 원형\n",
        "\n",
        "\n",
        "```\n",
        "cudaError_t cudaMemset(void *ptr, int value, size_t size)\n",
        "```\n",
        "\n",
        "1. void * ptr\n",
        "- 값을 초기화할 메모리 공간의 시작 주소\n",
        "\n",
        "2. int value\n",
        "- 각 바이트를 초기화할 값\n",
        "\n",
        "3. size_t size\n",
        "- 초기화할 메모리 공간의 크기\n"
      ],
      "metadata": {
        "id": "9knqSbmgq59i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**에러 코드 확인**\n",
        "\n",
        "* cudaGetErrorName()\n",
        "\n",
        "\n",
        "> CUDA API의 반환값 대부분은 에러코드(cudaError_t 열거형)이며 에러코드의 수는 그만큼 많음\n",
        "\n",
        "> 각 에러코드 번호는 버전에 따라 변경될 수 있으며 모든 에러코드를 알 수는 없기 때문에 함수를 통해 에러의 종류를 확인하면 좋음\n",
        "\n",
        "함수 원형\n",
        "\n",
        "\n",
        "```\n",
        "__host__ __device__ const char* cudaGetErrorName(cudaError_t error)\n",
        "```\n",
        "\n",
        "원형 앞에 __host__ 와 __device__ 가 모두 붙어 있는데, 이는 호스트와 디바이스 코드 모두에서 사용가능함을 말함\n"
      ],
      "metadata": {
        "id": "7DvdaDGDrzzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**디바이스 메모리 할당/초기화/해제 예제**\n",
        "\n"
      ],
      "metadata": {
        "id": "Ym4t0cl1tQpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <stdio.h>\n",
        "\n",
        "void checkDeviceMemory(void)\n",
        "{\n",
        "    size_t free, total;\n",
        "    cudaMemGetInfo(&free, &total);\n",
        "    printf(\"Device memory (free/total) = %lld/%lld bytes\\n\", free, total);\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "    int* dDataPtr;\n",
        "    cudaError_t errorCode;\n",
        "\n",
        "    checkDeviceMemory();\n",
        "    errorCode = cudaMalloc(&dDataPtr, sizeof(int)*1024*1024);\n",
        "    printf(\"cudaMalloc - %s\\n\", cudaGetErrorName(errorCode)); //메모리 할당 전\n",
        "    checkDeviceMemory();\n",
        "\n",
        "    errorCode = cudaMemset(dDataPtr, 0, sizeof(int)*1024*1024); //메모리 할당 후 가용 메모리 크기가 4MB 감소됨\n",
        "    printf(\"cudaMalloc - %s\\n\", cudaGetErrorName(errorCode));\n",
        "\n",
        "    errorCode = cudaFree(dDataPtr);\n",
        "    printf(\"cudaFree - %s\\n\", cudaGetErrorName(errorCode)); //Free선언 후 다시 메모리 공간이 반환됨을 확인 할 수 있음\n",
        "    checkDeviceMemory();\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l6nCM74tUgW",
        "outputId": "74d4215c-e74d-4702-9d3c-eabc1efabf66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device memory (free/total) = 15727656960/15835660288 bytes\n",
            "cudaMalloc - cudaSuccess\n",
            "Device memory (free/total) = 15723462656/15835660288 bytes\n",
            "cudaMalloc - cudaSuccess\n",
            "cudaFree - cudaSuccess\n",
            "Device memory (free/total) = 15727656960/15835660288 bytes\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cudaMalloc을 사용해서 int형 정수를 담을 수 있는 총 4MB의 공간을 할당하며, cudaMemset으로 모두 0으로 초기화하고 cudaFree로 메모리 공간을 해지하는 코드임\n",
        "\n",
        "\n",
        "**[checkDeviceMemory()]**\n",
        "\n",
        "디바이스 메모리의 총 크기와 현재 사용 가능한 공간의 크기를 반환해주는 함수로 cudaMemGetInfo()를 사용함\n",
        "\n",
        "free: 현재 가용 메모리 크기\n",
        "\n",
        "total: 사용하는 GPU가 가진 총 디바이스 메모리 크기\n",
        "\n",
        "> 사용하는 GPU보다 큰 메모리를 할당할 경우 에러 발생함"
      ],
      "metadata": {
        "id": "9zkyt80Uvlwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. 호스트 - 디바이스 메모리 데이터 복사**\n",
        "\n",
        "\n",
        "\n",
        "> 호스트 메모리와 디바이스 메모리는 서로 독립된 공간으로 다른 장치에 있는 데이터가 필요하다면 명시적인 데이터 복사 과정이 필요함\n",
        "\n",
        "**장치 간 데이터 복사**\n",
        "\n",
        "- cudaMemcpy()\n",
        "\n",
        "\n",
        "> CUDA 프로그램에서 장치 간 데이터 복사를 위해 사용하는 함수\n",
        "\n",
        "함수 원형\n",
        "\n",
        "\n",
        "```\n",
        "cudaError_t cudaMemcpy(void* dst, const void* src, size_t size, enum cudaMemcpyKind kind)\n",
        "```\n",
        "1. void* dist\n",
        "- 복사될 메모리 공간의 시작 주소를 담고 있는 포인터 변수\n",
        "\n",
        "2. const void* src\n",
        "- 복사할 원본 데이터가 들어있는 메모리 공간의 시작 주소를 담고 있는 포인터 변수\n",
        "\n",
        "3. size_t size\n",
        "- 복사할 데이터의 크기(바이트 단위)\n",
        "\n",
        "4. enum cudaMemcpyKind kind\n",
        "- cudaMemcpyKind의 열거형 변수로 데이터 복사의 방향을 설정하는 인자\n",
        "- 000ToXXX 형태로 000에서 XXX로 복사됨을 의미함\n",
        "- 이 방향은 함수의 첫번째, 두번째 인자의 방향과 일치해야함\n",
        "\n",
        "> cudaMemcpyDefault : dst와 src의 포인터 값에 의해 결정됨\n",
        "- 이 경우 CUDA런타임이 방향성을 판단해서 복사를 수행해줌\n",
        "- unified virtual addressing(호스트메모리와 디바이스 메모리를 하나의 공간처럼 가상화해줌)을 지원하는 시스템에서만 사용 가능\n",
        "- 이 방법보다는 명시적으로 지정하는 것이 더 권장됨\n",
        "\n",
        "<br>\n",
        "TIP!\n",
        "\n",
        "> CUDA 버전 6.0이상에서는 호스트 메모리와 디바이스 메모리를 하나의 논리적 주소 공간으로 사용할 수 있는 통합 메모리 기술을 지원한다. 이를 사용하면 명시적인 메모리 복사 없이 CUDA 프로그팸 작성가능하다. 그러나 높은 성능을 위해서는 명시적인 복사를 권장한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "1PKSZ3ZP-H20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**장치 간 데이터 복사 예제**"
      ],
      "metadata": {
        "id": "OWwM_knGg5Ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void printData(int * _dDataPtr)\n",
        "{\n",
        "    printf(\"%d\", _dDataPtr[threadIdx.x]);\n",
        "}\n",
        "\n",
        "__global__ void setData(int* _dDataPtr){  //배열의 모든 원소의 값을 2로 바꾸는 커널\n",
        "    _dDataPtr[threadIdx.x]=2;\n",
        "}\n",
        "\n",
        "int main(void){\n",
        "\n",
        "    int data[10]={0}; //호스트 메모리에 배열 만들기\n",
        "    for(int i=0; i<10; i++) data[i] =1; //값 초기화\n",
        "\n",
        "    int* dDataPtr;\n",
        "    cudaMalloc(&dDataPtr, sizeof(int)*10); //디바이스 메모리 할당\n",
        "    cudaMemset(dDataPtr, 0 ,sizeof(int)*10); //0으로 초기화\n",
        "\n",
        "    printf(\"Data in device:\");\n",
        "    printData<<<1,10>>> (dDataPtr);\n",
        "\n",
        "    cudaMemcpy(dDataPtr, data, sizeof(int)*10, cudaMemcpyHostToDevice); //호스트 메모리 -> 디바이스 메모리\n",
        "    printf(\"\\nHost->Device: \");\n",
        "    printData<<<1,10>>> (dDataPtr);\n",
        "\n",
        "    setData<<<1,10>>>(dDataPtr); //\n",
        "\n",
        "    cudaMemcpy(data, dDataPtr, sizeof(int)*10, cudaMemcpyDeviceToHost); //디바이스 메모리 -> 호스트 메모리\n",
        "    printf(\"\\nDevice->Host: \");\n",
        "    for(int i=0; i<10; i++) printf(\"%d\", data[i]);\n",
        "\n",
        "    cudaFree(dDataPtr);\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WreqmCy9g-xp",
        "outputId": "7f9c0b06-9d6e-4152-a6b0-64892ce72fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data in device:0000000000\n",
            "Host->Device: 1111111111\n",
            "Device->Host: 2222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.3 CUDA로 작성하는 벡터의 합 프로그램\n",
        "\n",
        "벡터 합을 구하는 호스트 프로그램"
      ],
      "metadata": {
        "id": "6xNhXpc_WW5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#define NUM_DATA 1024\n",
        "\n",
        "int main(void){\n",
        "    int *a, *b, *c;\n",
        "\n",
        "    int memSize = sizeof(int)*NUM_DATA;\n",
        "    a=new int[NUM_DATA]; memset(a, 0 ,memSize);\n",
        "    b=new int[NUM_DATA]; memset(b, 0 ,memSize);\n",
        "    c=new int[NUM_DATA]; memset(c, 0 ,memSize);\n",
        "\n",
        "    for(int i=0; i<NUM_DATA; i++){\n",
        "        a[i]= rand()%10;\n",
        "        b[i]=rand()%10;\n",
        "    }\n",
        "\n",
        "    for(int i=0; i<NUM_DATA; i++){\n",
        "        c[i] = a[i]+b[i];\n",
        "    }\n",
        "\n",
        "    delete[] a; delete[] b; delete[] c;\n",
        "    return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esUFq51BXSkd",
        "outputId": "2a83bf19-c8c0-4224-ada5-796906d0a204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**\"MEMSET\"이란?**\n",
        "\n",
        "\n",
        "> 메모리 블록을 특정 값으로 설정하는 데 사용되는 함수\n",
        "\n",
        "함수 원형\n",
        "\n",
        "\n",
        "```\n",
        "void *memset(void *ptr, int value, size_t num);\n",
        "```\n",
        "\n",
        "- memset 함수는 메모리를 1바이트 단위로 초기화한다\n",
        "\n",
        "잘못된 예시\n",
        "\n",
        "\n",
        "```\n",
        "memset(ptr, 1, 4) //4바이트를 1로 초기화\n",
        "```\n",
        "결과\n",
        "\n",
        "\n",
        "```\n",
        "00000001 00000001 00000001 00000001\n",
        "```\n",
        "\n",
        "> int 자료형은 하나당 4 bytes의 메모리 공간을 차지함\n",
        "\n",
        "> 하지만 memset 함수는 1byte 단위로 c를 집어넣기 때문에 실제로 메모리에는 다음과 같은 수로 가득 차게 됨\n",
        "\n",
        "> 그래서 대부분 0이나 Char 자료형으로 초기화 할때만 사용됨\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IaNaaSbvcDH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**벡터 합을 GPU로 처리하려면?**\n",
        "\n",
        "스켈레톤 코드\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "// The size of the vector\n",
        "#define NUM_DATA 1024\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int* _a, int* _b, int* _c) {\n",
        "\tint tID = threadIdx.x;\n",
        "\t_c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "\tint* a, * b, * c, * h_c;\t// Vectors on the host\n",
        "\tint* d_a, * d_b, * d_c;\t\t// Vectors on the device\n",
        "\n",
        "\tint memSize = sizeof(int) * NUM_DATA;\n",
        "\tprintf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\t// Memory allocation on the host-side\n",
        "\ta = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "\tb = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "\tc = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\th_c = new int[NUM_DATA]; memset(h_c, 0, memSize);\n",
        "\n",
        "\t// Data generation\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\ta[i] = rand() % 10;\n",
        "\t\tb[i] = rand() % 10;\n",
        "\t}\n",
        "\n",
        "\t// Vector sum on host (for performance comparision)\n",
        "\tfor (int i = 0; i < NUM_DATA; i++)\n",
        "\t\th_c[i] = a[i] + b[i];\n",
        "\n",
        "\t//****************************************//\n",
        "\t//******* Write your code - start ********//\n",
        "\n",
        "\t// 1. Memory allocation on the device-side (d_a, d_b, d_c)\n",
        "\n",
        "\t// 2. Data copy : Host (a, b) -> Device (d_a, d_b)\n",
        "\n",
        "\t// 3. Kernel call\n",
        "\t// vecAdd << <1, NUM_DATA >> > (d_a, d_b, d_c);\n",
        "\n",
        "\t// 4. Copy results : Device (d_c) -> Host (c)\n",
        "\n",
        "\t// 5. Release device memory (d_a, d_b, d_c)\n",
        "\n",
        "\t//******** Write your code - end *********//\n",
        "\t//****************************************//\n",
        "\n",
        "\t// Check results\n",
        "\tbool result = true;\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\tif (h_c[i] != c[i]) {\n",
        "\t\t\tprintf(\"[%d] The resutl is not matched! (%d, %d)\\n\"\n",
        "\t\t\t\t, i, h_c[i], c[i]);\n",
        "\t\t\tresult = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tif (result)\n",
        "\t\tprintf(\"GPU works well!\\n\");\n",
        "\n",
        "\t// Release host memory\n",
        "\tdelete[] a; delete[] b; delete[] c;\n",
        "\n",
        "\treturn 0;\n",
        "}\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "s0TgYbiPdAOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 정답"
      ],
      "metadata": {
        "id": "IIRl_INOgiZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "# include \"cuda_runtime.h\"\n",
        "# include \"device_launch_parameters.h\"\n",
        "\n",
        "# include <stdio.h>\n",
        "# include <stdlib.h>\n",
        "# include <string.h>\n",
        "\n",
        "// The size of the vector\n",
        "# define NUM_DATA 1024\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int* _a, int* _b, int* _c) {\n",
        "    int tID = threadIdx.x;\n",
        "    _c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "    int* a, * b, * c, * h_c;    // Vectors on the host\n",
        "    int* da, * db, * dc;        // Vectors on the device\n",
        "\n",
        "    int memSize = sizeof(int) * NUM_DATA;\n",
        "    printf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "    // Memory allocation on the host-side\n",
        "    a = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "    b = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "    c = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "    h_c = new int[NUM_DATA]; memset(h_c, 0, memSize);\n",
        "\n",
        "    // Data generation\n",
        "    for (int i = 0; i < NUM_DATA; i++) {\n",
        "        a[i] = rand() % 10;\n",
        "        b[i] = rand() % 10;\n",
        "    }\n",
        "\n",
        "    // Vector sum on host (for performance comparision)\n",
        "    for (int i = 0; i < NUM_DATA; i++)\n",
        "        h_c[i] = a[i] + b[i];\n",
        "\n",
        "    //****************************************//\n",
        "    //******* Write your code - start ********//\n",
        "\n",
        "    // 1. Memory allocation on the device-side (da, db, dc)\n",
        "    cudaMalloc(&da, memSize); cudaMemset(da, 0, memSize); //할당 및 초기화\n",
        "\t  cudaMalloc(&db, memSize); cudaMemset(db, 0, memSize);\n",
        "\t  cudaMalloc(&dc, memSize); cudaMemset(dc, 0, memSize);\n",
        "\n",
        "    // 2. Data copy : Host (a, b) -> Device (da, db)\n",
        "    cudaMemcpy(da, a, memSize, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(db, b, memSize, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // 3. Kernel call\n",
        "    vecAdd << <1, NUM_DATA >> > (da, db, dc);\n",
        "\n",
        "    // 4. Copy results : Device (dc) -> Host (c)\n",
        "    cudaMemcpy(c, dc, memSize, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // 5. Release device memory (da, db, dc)\n",
        "    cudaFree(da);\n",
        "    cudaFree(db);\n",
        "    cudaFree(dc);\n",
        "\n",
        "    //******** Write your code - end *********//\n",
        "    //****************************************//\n",
        "\n",
        "    // Check results\n",
        "    bool result = true;\n",
        "    for (int i = 0; i < NUM_DATA; i++) {\n",
        "        if (h_c[i] != c[i]) {\n",
        "            printf(\"[%d] The resutl is not matched! (%d, %d)\\n\"\n",
        "                , i, h_c[i], c[i]);\n",
        "            result = false;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (result)\n",
        "        printf(\"GPU works well!\\n\");\n",
        "\n",
        "    // Release host memory\n",
        "    delete[] a; delete[] b; delete[] c; //동적으로 할당된 배열 해제\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGG9HPZOgfFH",
        "outputId": "8d2b2577-c98c-435f-aaee-dd4622c075ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024 elements, memSize = 4096 bytes\n",
            "GPU works well!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">  CUDA 프로그램을 비롯한 병렬 처리 알고리즘의 설계 및 구현은 디버그 난이도가 높으므로 작성 초반부터 호스트 코드와 같이 검증된 연산 결과와 비교하길 권장함"
      ],
      "metadata": {
        "id": "Hj7hSIBUke-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.4 CUDA 알고리즘의 성능 측정\n",
        "\n",
        "GPU를 이용해 병렬 처리를 수행하는 이유는 연산 성능 향상을 위함임\n",
        "\n",
        "따라서 성능 측정이 필요함\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**1. 커널 수행 시간**\n",
        "\n",
        "\n",
        "> GPU연산은 커널 호출을 통해 진행되므로 CUDA 알고리즘 성능 측정을 위한 중요한 지점임\n",
        "\n",
        "\n",
        "```\n",
        "vecAdd<<<1, NUM_DATA>>> (da, db, dc); //커널 호출부\n",
        "```\n",
        "- 따라서 커널 호출 전에 시간 측정을 시작하고 커널 실행이 종료된 후 시간을 측정하면 커널 수행에 소요된 시간, 즉 GPU연산 시간을 측정할 수 있음\n",
        "\n",
        "**주의할 점**\n",
        "> 커널 호출 시 디바이스에게 명령을 전달한 후 프로그램 흐름의 제어권을 바로 호스트에게 반환한다는 점 즉, 호스트는 디바이스에게 커널 수행을 요청하고 바로 다음 작업을 진행함\n",
        "\n",
        "> 이는 호스트와 디바이스의 비동기적 수행이 가능하도록하는 특징임\n",
        "\n",
        ">따라서 디바이스가 수행 중인 작업이 끝날 때까지 대기하는 CUDA 동기화 함수 cudaDeviceSynchronize()를 커널 호출 다음에 넣고 시간 측정을 종료해야 커널의 수행 시간을 측정할 수 있음\n",
        "\n",
        "\n",
        "**데이터 복사는 완료되고 커널이 수행되는 걸까?**\n",
        "\n",
        "\n",
        "> 비동기적 특징이 있어도 CUDA API는 기본적으로 순차적으로 실행됨\n",
        "\n",
        "> CUDA API는 스트림(stream)이라는 일종의 큐(선입선출 데이터 구조)를 통해 관리됨 따라서 호스트 코드를 디바이스 코드 제어에만 사용할 시 동기화함수 사용이 필수는 아님 그러나 모두를 이용해 연산하는 경우나 정보를 주고받을 때에는 필요함\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "30Ym3xH-z6NM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. 데이터 전송 시간**\n",
        "\n",
        "\n",
        "> 장치 간 데이터복사는 GPU를 이용하기 위해 발생하는 추가 작업으로 CUDA 알고리즘에서 발생하는 부하임 따라서 CUDA 알고리즘 성능 판단의 지표가 될 수 있음\n",
        "\n",
        "> 호스트에서 디바이스로 디바이스에서 호스트로 메모리 복사하는 부분의 시작과 끝에 시간 측정 시작 및 종료를 해주면 확인할 수 있음\n",
        "\n",
        ">cudaMemcpy는 호스트코드와 동기적으로 수행되므로 cudaDeviceSynchronize()함수가 필요하지 않음\n",
        "\n",
        "예시\n",
        "\n",
        "\n",
        "```\n",
        "//시간 측정 시작\n",
        "cudaMemcpy(da, a, memSize, cudaMemcpyHostToDevice);\n",
        "//시간 측정 종료\n",
        "```\n",
        "\n",
        "- 이외에도 CUDA를 통해 GPU를 사용하기 위해 추가 작업이 있다면 해당 작업에 소요되는 시간도 포함해서 성능을 올바르게 확인할 수 있음\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lqg4HNCxzd6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CUDA 기반 벡터 합 프로그램의 성능 측정 및 분석**\n",
        "> 교재에서는 DS_timer을 사용하는데 이는 폴더에 파일을 넣어줘야해서 다른 방식을 찾아봐야할 것 같음\n",
        "\n",
        "< NVIDIA에서 권고하는 방식 >\n",
        "\n",
        "\n",
        "```\n",
        "// cudaEvent create\n",
        "cudaEvent_t start, stop;\n",
        "cudaEventCreate(&start);\n",
        "cudaEventCreate(&stop);\n",
        "\n",
        ". . .\n",
        "\n",
        "cudaEventRecord(start, 0);\n",
        "\n",
        "// 실행 시간을 측정할 GPU 코드\n",
        "\n",
        "cudaEventRecord(stop, 0);\n",
        "cudaEventSynchronize(stop);\n",
        "float elapsedTime;\n",
        "cudaEventElapsedTime(&elapsedTime, start, stop);\n",
        "\n",
        ". . .\n",
        "\n",
        "// cudaEvent destroy\n",
        "cudaEventDestroy(start);\n",
        "cudaEventDestroy(stop);\n",
        "```\n",
        "\n",
        "- GPU작업만 측정하므로 오버헤드가 적으며 높은 정확도를 보임\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "< 만약 CPU와 GPU 통합적으로 측정한다면? >\n",
        "\n",
        "1. std::chrono\n",
        "\n",
        "```\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    \n",
        "    // CUDA 코드 실행\n",
        "    \n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> elapsed = end - start;\n",
        "\n",
        "    std::cout << \"Elapsed time: \" << elapsed.count() << \" seconds\" << std::endl;\n",
        "```\n",
        "- 커널 실행 및 데이터 전송을 포함한 전체 프로그램의 실행 시간을 측정할 때 유용함\n",
        "- 그러나 그만큼 동기화에 대해 주의를 기울여서 측정할 필요가 있음\n",
        "- clock()은 초당 1,000번의 측정을 통해 1ms의 시간을 측정할 수 있음\n",
        "- 단순한 프로그램 시간 측정에 적합\n",
        "<br> <br>\n",
        "\n",
        "2. QPC(QueryPerformanceCounter())\n",
        "\n",
        "\n",
        "```\n",
        "#include <stdio.h>\n",
        "#include <Windows.h>\n",
        "int main(void){\n",
        "\n",
        "\tLARGE_INTEGER ticksPerSec;\n",
        "\tLARGE_INTEGER start, end, diff;\n",
        "    \n",
        "\tQueryPerformanceFrequency(&ticksPerSec);\n",
        "\tQueryPerformanceCounter(&start);\n",
        "\t// 시간을 측정하고 싶은 작업(예: 함수 호출)을 이곳에 삽입\n",
        "    \n",
        "\tQueryPerformanceCounter(&end);\n",
        "\t// 측정값으로부터 실행시간 계산\n",
        "\tdiff.QuadPart = end.QuadPart - start.QuadPart;\n",
        "\tprintf(\"time: %.12f sec\\n\\n\", ((double)diff.QuadPart/(double)ticksPerSec.QuadPart));\n",
        "\treturn 0;\n",
        "}\n",
        "출처: https://udangtangtang-cording-oldcast1e.tistory.com/20 [우당탕탕 코딩 제작소:티스토리]\n",
        "```\n",
        "- 메인보드에 고해상도의 타이머가 존재하는데 이를 이용하여 특정 실행 시점들의 CPU 클럭수들을 얻어온 후 그 차이를 이용하여 작업 시간을 구함\n",
        "- clock() 함수와 달리 1us 이하의 시간까지 측정\n",
        "- 고정밀 프로그램 시간 측정에 적합 그러나 clock()과 마찬가지로 동기화에 주의를 기울여야함\n",
        "- window환경에서만 사용가능함\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qTWMk2EI05NI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CUDA 기반 벡터 합 프로그램의 성능 측정**\n",
        "\n",
        "host코드와 비교 측정을 위해 QPC 방법을 사용하고자 함"
      ],
      "metadata": {
        "id": "cdoK8h_AQtp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <windows.h>\n",
        "\n",
        "// The size of the vector\n",
        "#define NUM_DATA 1024\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int* _a, int* _b, int* _c) {\n",
        "\tint tID = threadIdx.x;\n",
        "\t_c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "\n",
        "\tint* a, * b, * c, * hc;\t// Vectors on the host\n",
        "\tint* da, * db, * dc;\t// Vectors on the device\n",
        "\n",
        "\tint memSize = sizeof(int) * NUM_DATA;\n",
        "\tprintf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\t// Memory allocation on the host-side\n",
        "\ta = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "\tb = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "\tc = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\thc = new int[NUM_DATA]; memset(hc, 0, memSize);\n",
        "\n",
        "\t// Data generation\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\ta[i] = rand() % 10;\n",
        "\t\tb[i] = rand() % 10;\n",
        "\t}\n",
        "\n",
        "  LARGE_INTEGER frequency, hostStart, hostEnd;\n",
        "  double hostTime, totalTime, h2dTime, kernelTime, d2hTime;\n",
        "  QueryPerformanceFrequency(&frequency);\n",
        "\n",
        "\t// Vector sum on host (for performance comparision)\n",
        "  QueryPerformanceCounter(&hostStart);\n",
        "\tfor (int i = 0; i < NUM_DATA; i++)\n",
        "\t\thc[i] = a[i] + b[i];\n",
        "  QueryPerformanceCounter(&hostEnd);\n",
        "  hostTime = static_cast<double>(hostEnd.QuadPart - hostStart.QuadPart) / frequency.QuadPart * 1000;\n",
        "\n",
        "\t// Memory allocation on the device-side\n",
        "\tcudaMalloc(&da, memSize); cudaMemset(da, 0, memSize);\n",
        "\tcudaMalloc(&db, memSize); cudaMemset(db, 0, memSize);\n",
        "\tcudaMalloc(&dc, memSize); cudaMemset(dc, 0, memSize);\n",
        "\n",
        "  LARGE_INTEGER deviceStart, deviceEnd;\n",
        "  QueryPerformanceCounter(&deviceStart);\n",
        "\n",
        "\t// Data copy : Host -> Device\n",
        "\tLARGE_INTEGER h2dStart, h2dEnd;\n",
        "\tQueryPerformanceCounter(&h2dStart);\n",
        "\tcudaMemcpy(da, a, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(db, b, memSize, cudaMemcpyHostToDevice);\n",
        "\tQueryPerformanceCounter(&h2dEnd);\n",
        "  h2dTime = static_cast<double>(h2dEnd.QuadPart - h2dEnd.QuadPart) / frequency.QuadPart * 1000;\n",
        "\n",
        "\t// Kernel call\n",
        "\tLARGE_INTEGER kernelStart, kernelEnd;\n",
        "\tQueryPerformanceCounter(&kernelStart);\n",
        "\tvecAdd <<<1, NUM_DATA >>> (da, db, dc);\n",
        "\tcudaDeviceSynchronize(); // synchronization function\n",
        "  QueryPerformanceCounter(&endKernel);\n",
        "  kernelTime = static_cast<double>(kernelEnd.QuadPart - kernelStart.QuadPart) / frequency.QuadPart * 1000;\n",
        "\n",
        "\t// Copy results : Device -> Host\n",
        "  LARGE_INTEGER d2hStart, d2hEnd;\n",
        "\tQueryPerformanceCounter(&d2hStart);\n",
        "\tcudaMemcpy(c, dc, memSize, cudaMemcpyDeviceToHost);\n",
        "  QueryPerformanceCounter(&d2hEnd);\n",
        "  d2hTime = static_cast<double>(d2hEnd.QuadPart - d2hStart.QuadPart) / frequency.QuadPart * 1000;\n",
        "\n",
        "\tQueryPerformanceCounter(&deviceEnd);\n",
        "  totalTime = static_cast<double>(deviceEnd.QuadPart - deviceStart.QuadPart) / frequency.QuadPart * 1000;\n",
        "\n",
        "\t// Release device memory\n",
        "\tcudaFree(da); cudaFree(db); cudaFree(dc);\n",
        "\n",
        "  printf(\"Host Time: %f ms\\n\", hostTime);\n",
        "  printf(\"Host -> Device: %f ms\\n\", h2dTime);\n",
        "  printf(\"Kernel: %f ms\\n\", kernelTime);\n",
        "  printf(\"Device -> Host: %f ms\\n\", d2hTime);\n",
        "  printf(\"CUDA Total Time: %f ms\\n\", totalTime);\n",
        "\n",
        "\t// Check results\n",
        "\tbool result = true;\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\tif (hc[i] != c[i]) {\n",
        "\t\t\tprintf(\"[%d] The result is not matched! (%d, %d)\\n\"\n",
        "\t\t\t\t, i, hc[i], c[i]);\n",
        "\t\t\tresult = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tif (result)\n",
        "\t\tprintf(\"GPU works well!\\n\");\n",
        "\n",
        "\t// Release host memory\n",
        "\tdelete[] a; delete[] b; delete[] c;\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYlysDemQ2Tk",
        "outputId": "1aa57c78-eacd-4eac-8860-fbd56a522434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmp8t2qwnxn/a177d02a-3b32-4da3-abab-149193fd245c/single_file.cu:7:10: fatal error: windows.h: No such file or directory\n",
            "    7 | #include <windows.h>\n",
            "      |          ^~~~~~~~~~~\n",
            "compilation terminated.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "작성은 호기롭게 다했는데 코랩에서는 window.h라이브러리가 안된다!!!!!!!\n",
        "\n",
        "그래서 chrono 방식과 cudaEvent를 혼합해서 사용해야겠다\n",
        "\n",
        "**chrono & cudaEvent**"
      ],
      "metadata": {
        "id": "1rWL13WDXGNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "\n",
        "// The size of the vector\n",
        "#define NUM_DATA 1024\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int* _a, int* _b, int* _c) {\n",
        "\tint tID = threadIdx.x;\n",
        "\t_c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "\n",
        "\tint* a, * b, * c, * hc;\t// Vectors on the host\n",
        "\tint* da, * db, * dc;\t// Vectors on the device\n",
        "\n",
        "\tint memSize = sizeof(int) * NUM_DATA;\n",
        "\tprintf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\t// Memory allocation on the host-side\n",
        "\ta = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "\tb = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "\tc = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\thc = new int[NUM_DATA]; memset(hc, 0, memSize);\n",
        "\n",
        "\t// Data generation\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\ta[i] = rand() % 10;\n",
        "\t\tb[i] = rand() % 10;\n",
        "\t}\n",
        "\n",
        "\n",
        "\t// Vector sum on host (for performance comparision)\n",
        "  auto start = std::chrono::high_resolution_clock::now();\n",
        "\tfor (int i = 0; i < NUM_DATA; i++)\n",
        "\t\thc[i] = a[i] + b[i];\n",
        "  auto end = std::chrono::high_resolution_clock::now();\n",
        "  // 밀리초 단위로 경과 시간 계산 (소수점 포함)\n",
        "  std::chrono::duration<double, std::milli> elapsed = end - start;\n",
        "\n",
        "\n",
        "  cudaEvent_t totalStart, totalStop, h2dStart, h2dStop, kernelStart, kernelStop, d2hStart, d2hStop;\n",
        "  cudaEventCreate(&totalStart);\n",
        "  cudaEventCreate(&totalStop);\n",
        "  cudaEventCreate(&h2dStart);\n",
        "  cudaEventCreate(&h2dStop);\n",
        "  cudaEventCreate(&kernelStart);\n",
        "  cudaEventCreate(&kernelStop);\n",
        "  cudaEventCreate(&d2hStart);\n",
        "  cudaEventCreate(&d2hStop);\n",
        "\n",
        "\n",
        "\t// Memory allocation on the device-side\n",
        "\tcudaMalloc(&da, memSize); cudaMemset(da, 0, memSize);\n",
        "\tcudaMalloc(&db, memSize); cudaMemset(db, 0, memSize);\n",
        "\tcudaMalloc(&dc, memSize); cudaMemset(dc, 0, memSize);\n",
        "\n",
        "  cudaEventRecord(totalStart, 0);\n",
        "\n",
        "\t// Data copy : Host -> Device\n",
        "\tcudaEventRecord(h2dStart, 0);\n",
        "\tcudaMemcpy(da, a, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(db, b, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaEventRecord(h2dStop, 0);\n",
        "  cudaEventSynchronize(h2dStop);\n",
        "  float h2dTime;\n",
        "  cudaEventElapsedTime(&h2dTime, h2dStart, h2dStop);\n",
        "\n",
        "\t// Kernel call\n",
        "\tcudaEventRecord(kernelStart, 0);\n",
        "\tvecAdd <<<1, NUM_DATA >>> (da, db, dc);\n",
        "\tcudaDeviceSynchronize(); // synchronization function\n",
        "  cudaEventRecord(kernelStop, 0);\n",
        "  cudaEventSynchronize(kernelStop);\n",
        "  float kernelTime;\n",
        "  cudaEventElapsedTime(&kernelTime, kernelStart, kernelStop);\n",
        "\n",
        "\t// Copy results : Device -> Host\n",
        "  cudaEventRecord(d2hStart, 0);\n",
        "\tcudaMemcpy(c, dc, memSize, cudaMemcpyDeviceToHost);\n",
        "  cudaEventRecord(d2hStop, 0);\n",
        "  cudaEventSynchronize(d2hStop);\n",
        "  float d2hTime;\n",
        "  cudaEventElapsedTime(&d2hTime, d2hStart, d2hStop);\n",
        "\n",
        "\tcudaEventRecord(totalStop, 0);\n",
        "  cudaEventSynchronize(totalStop);\n",
        "  float totalTime;\n",
        "  cudaEventElapsedTime(&totalTime, totalStart, totalStop);\n",
        "\n",
        "\t// Release device memory\n",
        "\tcudaFree(da); cudaFree(db); cudaFree(dc);\n",
        "\n",
        "  // 결과 출력 (밀리초 단위, 소수점 포함)\n",
        "  std::cout << \"Host time: \" << elapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Host -> Device: \" << h2dTime << \" ms\" << std::endl;\n",
        "  std::cout<<\"Kernel: \" << kernelTime << \" ms\" << std::endl;\n",
        "  std::cout<<\"Device -> Host: \" << d2hTime << \" ms\" << std::endl;\n",
        "  std::cout<<\"CUDA Total Time: \" << totalTime << \" ms\" << std::endl;\n",
        "\n",
        "\t// Check results\n",
        "\tbool result = true;\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\tif (hc[i] != c[i]) {\n",
        "\t\t\tprintf(\"[%d] The result is not matched! (%d, %d)\\n\"\n",
        "\t\t\t\t, i, hc[i], c[i]);\n",
        "\t\t\tresult = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tif (result)\n",
        "\t\tprintf(\"GPU works well!\\n\");\n",
        "\n",
        "\t// Release host memory\n",
        "\tdelete[] a; delete[] b; delete[] c;\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5es1CnJNTJmz",
        "outputId": "ea439865-000d-459a-95be-8a6012ad6927"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024 elements, memSize = 4096 bytes\n",
            "Host time: 0.004024 ms\n",
            "Host -> Device: 0.026624 ms\n",
            "Kernel: 0.224288 ms\n",
            "Device -> Host: 0.02 ms\n",
            "CUDA Total Time: 0.301152 ms\n",
            "GPU works well!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "생각과는 다른 결과!!!\n",
        "\n",
        "**CPU가 GPU보다 빠르다!**\n",
        "\n",
        "이유:\n",
        "\n",
        "> 1024의 벡터 크기는 GPU연산 성능을 발휘하기에는 턱없이 적은 숫자임\n",
        "> 추가로 CUDA 함수 사용은 CUDA API 호출을 위한 기본 비용이 존재하기에 일정시간을 필요로 함\n",
        "\n",
        "**그러면 벡터 크기를 늘린다면?**\n",
        "\n"
      ],
      "metadata": {
        "id": "IY5NajY_VnZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "\n",
        "// The size of the vector\n",
        "#define NUM_DATA 1048576\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int* _a, int* _b, int* _c) {\n",
        "\tint tID = threadIdx.x;\n",
        "\t_c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "\n",
        "\tint* a, * b, * c, * hc;\t// Vectors on the host\n",
        "\tint* da, * db, * dc;\t// Vectors on the device\n",
        "\n",
        "\tint memSize = sizeof(int) * NUM_DATA;\n",
        "\tprintf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\t// Memory allocation on the host-side\n",
        "\ta = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "\tb = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "\tc = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\thc = new int[NUM_DATA]; memset(hc, 0, memSize);\n",
        "\n",
        "\t// Data generation\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\ta[i] = rand() % 10;\n",
        "\t\tb[i] = rand() % 10;\n",
        "\t}\n",
        "\n",
        "\n",
        "\t// Vector sum on host (for performance comparision)\n",
        "  auto start = std::chrono::high_resolution_clock::now();\n",
        "\tfor (int i = 0; i < NUM_DATA; i++)\n",
        "\t\thc[i] = a[i] + b[i];\n",
        "  auto end = std::chrono::high_resolution_clock::now();\n",
        "  // 밀리초 단위로 경과 시간 계산 (소수점 포함)\n",
        "  std::chrono::duration<double, std::milli> elapsed = end - start;\n",
        "\n",
        "\n",
        "  cudaEvent_t totalStart, totalStop, h2dStart, h2dStop, kernelStart, kernelStop, d2hStart, d2hStop;\n",
        "  cudaEventCreate(&totalStart);\n",
        "  cudaEventCreate(&totalStop);\n",
        "  cudaEventCreate(&h2dStart);\n",
        "  cudaEventCreate(&h2dStop);\n",
        "  cudaEventCreate(&kernelStart);\n",
        "  cudaEventCreate(&kernelStop);\n",
        "  cudaEventCreate(&d2hStart);\n",
        "  cudaEventCreate(&d2hStop);\n",
        "\n",
        "\n",
        "\t// Memory allocation on the device-side\n",
        "\tcudaMalloc(&da, memSize); cudaMemset(da, 0, memSize);\n",
        "\tcudaMalloc(&db, memSize); cudaMemset(db, 0, memSize);\n",
        "\tcudaMalloc(&dc, memSize); cudaMemset(dc, 0, memSize);\n",
        "\n",
        "  cudaEventRecord(totalStart, 0);\n",
        "\n",
        "\t// Data copy : Host -> Device\n",
        "\tcudaEventRecord(h2dStart, 0);\n",
        "\tcudaMemcpy(da, a, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(db, b, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaEventRecord(h2dStop, 0);\n",
        "  cudaEventSynchronize(h2dStop);\n",
        "  float h2dTime;\n",
        "  cudaEventElapsedTime(&h2dTime, h2dStart, h2dStop);\n",
        "\n",
        "\t// Kernel call\n",
        "\tcudaEventRecord(kernelStart, 0);\n",
        "\tvecAdd <<<1, NUM_DATA >>> (da, db, dc);\n",
        "\tcudaDeviceSynchronize(); // synchronization function\n",
        "  cudaEventRecord(kernelStop, 0);\n",
        "  cudaEventSynchronize(kernelStop);\n",
        "  float kernelTime;\n",
        "  cudaEventElapsedTime(&kernelTime, kernelStart, kernelStop);\n",
        "\n",
        "\t// Copy results : Device -> Host\n",
        "  cudaEventRecord(d2hStart, 0);\n",
        "\tcudaMemcpy(c, dc, memSize, cudaMemcpyDeviceToHost);\n",
        "  cudaEventRecord(d2hStop, 0);\n",
        "  cudaEventSynchronize(d2hStop);\n",
        "  float d2hTime;\n",
        "  cudaEventElapsedTime(&d2hTime, d2hStart, d2hStop);\n",
        "\n",
        "\tcudaEventRecord(totalStop, 0);\n",
        "  cudaEventSynchronize(totalStop);\n",
        "  float totalTime;\n",
        "  cudaEventElapsedTime(&totalTime, totalStart, totalStop);\n",
        "\n",
        "\t// Release device memory\n",
        "\tcudaFree(da); cudaFree(db); cudaFree(dc);\n",
        "\n",
        "  // 결과 출력 (밀리초 단위, 소수점 포함)\n",
        "  std::cout << \"Host time: \" << elapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Host -> Device: \" << h2dTime << \" ms\" << std::endl;\n",
        "  std::cout<<\"Kernel: \" << kernelTime << \" ms\" << std::endl;\n",
        "  std::cout<<\"Device -> Host: \" << d2hTime << \" ms\" << std::endl;\n",
        "  std::cout<<\"CUDA Total Time: \" << totalTime << \" ms\" << std::endl;\n",
        "\n",
        "\t// Check results\n",
        "\tbool result = true;\n",
        "\tfor (int i = 0; i < 1; i++) {\n",
        "\t\tif (hc[i] != c[i]) {\n",
        "\t\t\tprintf(\"[%d] The result is not matched! (%d, %d)\\n\"\n",
        "\t\t\t\t, i, hc[i], c[i]);\n",
        "\t\t\tresult = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tif (result)\n",
        "\t\tprintf(\"GPU works well!\\n\");\n",
        "\n",
        "\t// Release host memory\n",
        "\tdelete[] a; delete[] b; delete[] c;\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQR4RH1ZW3kE",
        "outputId": "9c233399-05c2-4d3d-9383-bbb610e53f45"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1048576 elements, memSize = 4194304 bytes\n",
            "Host time: 4.26018 ms\n",
            "Host -> Device: 2.22157 ms\n",
            "Kernel: 0.328736 ms\n",
            "Device -> Host: 1.13136 ms\n",
            "CUDA Total Time: 3.71702 ms\n",
            "[0] The result is not matched! (9, 0)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "속도 확인을 위해 결과 출력은 1만 일단 해보았음(출력이 너무 길어서 코랩이 삭제해버린다,,,)\n",
        "\n",
        "결과:  \n",
        ">CUDA 알고리즘이 속도 면에서는 더 빨라졌지만\n",
        "대부분 연산 결과가 일치하지 않는 다는 메시지가 출력되었음\n",
        "\n",
        "이는 CUDA 스레드 계층 구조 및 실행 모델의 이해가 필요함\n",
        "\n",
        "4장에서 계속,,,,,\n"
      ],
      "metadata": {
        "id": "j2YebQjaYJ7c"
      }
    }
  ]
}