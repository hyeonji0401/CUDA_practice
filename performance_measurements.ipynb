{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPUaOAGCihA/v/lAJJvzpfs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonji0401/CUDA_practice/blob/main/performance_measurements.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **성능 측정 테스트**\n",
        "\n",
        "\n",
        "이전 벡터의 합 성능 측정 당시 사용한 chrono 방식과 cudaEvent 방식으로 비교해서 측정해본 뒤 결과 확인해보기\n",
        "\n",
        "\n",
        "**1. chrono 방식**"
      ],
      "metadata": {
        "id": "6mljiRRG478y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "\n",
        "// The size of the vector\n",
        "#define NUM_DATA 1024\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int* _a, int* _b, int* _c) {\n",
        "\tint tID = threadIdx.x;\n",
        "\t_c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "\n",
        "\tint* a, * b, * c, * hc;\t// Vectors on the host\n",
        "\tint* da, * db, * dc;\t// Vectors on the device\n",
        "\n",
        "\tint memSize = sizeof(int) * NUM_DATA;\n",
        "\tprintf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\t// Memory allocation on the host-side\n",
        "\ta = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "\tb = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "\tc = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\thc = new int[NUM_DATA]; memset(hc, 0, memSize);\n",
        "\n",
        "\t// Data generation\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\ta[i] = rand() % 10;\n",
        "\t\tb[i] = rand() % 10;\n",
        "\t}\n",
        "\n",
        "\n",
        "\t// Vector sum on host (for performance comparision)\n",
        "  auto hostStart = std::chrono::high_resolution_clock::now();\n",
        "\tfor (int i = 0; i < NUM_DATA; i++)\n",
        "\t\thc[i] = a[i] + b[i];\n",
        "  auto hostEnd = std::chrono::high_resolution_clock::now();\n",
        "  // 밀리초 단위로 경과 시간 계산 (소수점 포함)\n",
        "  std::chrono::duration<double, std::milli> hostElapsed = hostEnd - hostStart;\n",
        "\n",
        "\n",
        "\t// Memory allocation on the device-side\n",
        "\tcudaMalloc(&da, memSize); cudaMemset(da, 0, memSize);\n",
        "\tcudaMalloc(&db, memSize); cudaMemset(db, 0, memSize);\n",
        "\tcudaMalloc(&dc, memSize); cudaMemset(dc, 0, memSize);\n",
        "\n",
        "  auto GPUstart = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "\t// Data copy : Host -> Device\n",
        "\tauto h2dStart = std::chrono::high_resolution_clock::now();\n",
        "\tcudaMemcpy(da, a, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(db, b, memSize, cudaMemcpyHostToDevice);\n",
        "\tauto h2dEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> h2dElapsed = h2dEnd - h2dStart;\n",
        "\n",
        "\t// Kernel call\n",
        "\tauto kernelStart = std::chrono::high_resolution_clock::now();\n",
        "\tvecAdd <<<1, NUM_DATA >>> (da, db, dc);\n",
        "\tcudaDeviceSynchronize(); // synchronization function\n",
        "  auto kernelEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> kernelElapsed = kernelEnd - kernelStart;\n",
        "\n",
        "\n",
        "\t// Copy results : Device -> Host\n",
        "  auto d2hStart = std::chrono::high_resolution_clock::now();\n",
        "\tcudaMemcpy(c, dc, memSize, cudaMemcpyDeviceToHost);\n",
        "  auto d2hEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> d2hElapsed = d2hEnd - d2hStart;\n",
        "\n",
        "\tauto GPUend = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> GPUelapsed = GPUend - GPUstart;\n",
        "\n",
        "\t// Release device memory\n",
        "\tcudaFree(da); cudaFree(db); cudaFree(dc);\n",
        "\n",
        "  // 결과 출력 (밀리초 단위, 소수점 포함)\n",
        "  std::cout << \"Host time: \" << hostElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Host -> Device: \" << h2dElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Kernel: \" << kernelElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Device -> Host: \" << d2hElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"CUDA Total Time: \" << GPUelapsed.count() << \" ms\" << std::endl;\n",
        "\n",
        "\t// Check results\n",
        "\tbool result = true;\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\tif (hc[i] != c[i]) {\n",
        "\t\t\tprintf(\"[%d] The result is not matched! (%d, %d)\\n\"\n",
        "\t\t\t\t, i, hc[i], c[i]);\n",
        "\t\t\tresult = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tif (result)\n",
        "\t\tprintf(\"GPU works well!\\n\");\n",
        "\n",
        "\t// Release host memory\n",
        "\tdelete[] a; delete[] b; delete[] c;\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVYcio5F55Rc",
        "outputId": "5786e28b-aca3-4748-b8de-c7d5fd009b33"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024 elements, memSize = 4096 bytes\n",
            "Host time: 0.002938 ms\n",
            "Host -> Device: 0.022235 ms\n",
            "Kernel: 0.152926 ms\n",
            "Device -> Host: 0.016128 ms\n",
            "CUDA Total Time: 0.191843 ms\n",
            "GPU works well!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3번 실행 결과 평균**\n",
        "\n",
        "**Host :** 0.003306 ms\n",
        "\n",
        "**Host -> Device :** 0.072495 ms\n",
        "\n",
        "**Kernel:** 0.10874393 ms\n",
        "\n",
        "**Device -> Host:** 0.0171623 ms\n",
        "\n",
        "**CUDA Total time:** 0.210348 ms"
      ],
      "metadata": {
        "id": "9JbjJEq6_xWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. CUDA Event 방식**\n",
        "\n",
        "> CUDA event방식으로는 CPU 성능 측정이 불가함으로 호스트 코드 외 측정"
      ],
      "metadata": {
        "id": "T6QumwvkB3yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "\n",
        "// The size of the vector\n",
        "#define NUM_DATA 1024\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int* _a, int* _b, int* _c) {\n",
        "\tint tID = threadIdx.x;\n",
        "\t_c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "\n",
        "\tint* a, * b, * c, * hc;\t// Vectors on the host\n",
        "\tint* da, * db, * dc;\t// Vectors on the device\n",
        "\n",
        "\tint memSize = sizeof(int) * NUM_DATA;\n",
        "\tprintf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\t// Memory allocation on the host-side\n",
        "\ta = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "\tb = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "\tc = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\thc = new int[NUM_DATA]; memset(hc, 0, memSize);\n",
        "\n",
        "\t// Data generation\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\ta[i] = rand() % 10;\n",
        "\t\tb[i] = rand() % 10;\n",
        "\t}\n",
        "\n",
        "\n",
        "\t// Vector sum on host (for performance comparision)\n",
        "  auto start = std::chrono::high_resolution_clock::now();\n",
        "\tfor (int i = 0; i < NUM_DATA; i++)\n",
        "\t\thc[i] = a[i] + b[i];\n",
        "  auto end = std::chrono::high_resolution_clock::now();\n",
        "  // 밀리초 단위로 경과 시간 계산 (소수점 포함)\n",
        "  std::chrono::duration<double, std::milli> elapsed = end - start;\n",
        "\n",
        "\n",
        "  cudaEvent_t totalStart, totalStop, h2dStart, h2dStop, kernelStart, kernelStop, d2hStart, d2hStop;\n",
        "  cudaEventCreate(&totalStart);\n",
        "  cudaEventCreate(&totalStop);\n",
        "  cudaEventCreate(&h2dStart);\n",
        "  cudaEventCreate(&h2dStop);\n",
        "  cudaEventCreate(&kernelStart);\n",
        "  cudaEventCreate(&kernelStop);\n",
        "  cudaEventCreate(&d2hStart);\n",
        "  cudaEventCreate(&d2hStop);\n",
        "\n",
        "\n",
        "\t// Memory allocation on the device-side\n",
        "\tcudaMalloc(&da, memSize); cudaMemset(da, 0, memSize);\n",
        "\tcudaMalloc(&db, memSize); cudaMemset(db, 0, memSize);\n",
        "\tcudaMalloc(&dc, memSize); cudaMemset(dc, 0, memSize);\n",
        "\n",
        "  cudaEventRecord(totalStart, 0);\n",
        "\n",
        "\t// Data copy : Host -> Device\n",
        "\tcudaEventRecord(h2dStart, 0);\n",
        "\tcudaMemcpy(da, a, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(db, b, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaEventRecord(h2dStop, 0);\n",
        "  cudaEventSynchronize(h2dStop);\n",
        "  float h2dTime;\n",
        "  cudaEventElapsedTime(&h2dTime, h2dStart, h2dStop);\n",
        "\n",
        "\t// Kernel call\n",
        "\tcudaEventRecord(kernelStart, 0);\n",
        "\tvecAdd <<<1, NUM_DATA >>> (da, db, dc);\n",
        "  cudaEventRecord(kernelStop, 0);\n",
        "  cudaEventSynchronize(kernelStop);\n",
        "  float kernelTime;\n",
        "  cudaEventElapsedTime(&kernelTime, kernelStart, kernelStop);\n",
        "\n",
        "\t// Copy results : Device -> Host\n",
        "  cudaEventRecord(d2hStart, 0);\n",
        "\tcudaMemcpy(c, dc, memSize, cudaMemcpyDeviceToHost);\n",
        "  cudaEventRecord(d2hStop, 0);\n",
        "  cudaEventSynchronize(d2hStop);\n",
        "  float d2hTime;\n",
        "  cudaEventElapsedTime(&d2hTime, d2hStart, d2hStop);\n",
        "\n",
        "\tcudaEventRecord(totalStop, 0);\n",
        "  cudaEventSynchronize(totalStop);\n",
        "  float totalTime;\n",
        "  cudaEventElapsedTime(&totalTime, totalStart, totalStop);\n",
        "\n",
        "\t// Release device memory\n",
        "\tcudaFree(da); cudaFree(db); cudaFree(dc);\n",
        "\n",
        "  // 결과 출력 (밀리초 단위, 소수점 포함)\n",
        "  std::cout << \"Host time: \" << elapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Host -> Device: \" << h2dTime << \" ms\" << std::endl;\n",
        "  std::cout<<\"Kernel: \" << kernelTime << \" ms\" << std::endl;\n",
        "  std::cout<<\"Device -> Host: \" << d2hTime << \" ms\" << std::endl;\n",
        "  std::cout<<\"CUDA Total Time: \" << totalTime << \" ms\" << std::endl;\n",
        "\n",
        "\t// Check results\n",
        "\tbool result = true;\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\tif (hc[i] != c[i]) {\n",
        "\t\t\tprintf(\"[%d] The result is not matched! (%d, %d)\\n\"\n",
        "\t\t\t\t, i, hc[i], c[i]);\n",
        "\t\t\tresult = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tif (result)\n",
        "\t\tprintf(\"GPU works well!\\n\");\n",
        "\n",
        "\t// Release host memory\n",
        "\tdelete[] a; delete[] b; delete[] c;\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMLl_u9VCYNJ",
        "outputId": "a39e5fc9-4074-44dc-f8ba-46cac6727b74"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024 elements, memSize = 4096 bytes\n",
            "Host time: 0.002987 ms\n",
            "Host -> Device: 0.034208 ms\n",
            "Kernel: 0.191776 ms\n",
            "Device -> Host: 0.01856 ms\n",
            "CUDA Total Time: 0.273536 ms\n",
            "GPU works well!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3번 실행 결과 평균**\n",
        "\n",
        "**Host -> Device :** 0.0260293 ms\n",
        "\n",
        "**Kernel:** 0.1693626667 ms\n",
        "\n",
        "**Device -> Host:** 0.01904 ms\n",
        "\n",
        "**CUDA Total time:** 0.2434773 ms"
      ],
      "metadata": {
        "id": "l_0ihE0lCzmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**만약 chrono 방식에서 동기화가 이루어지지 않는다면?**"
      ],
      "metadata": {
        "id": "O_wbz8zbEMsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "\n",
        "// The size of the vector\n",
        "#define NUM_DATA 1024\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int* _a, int* _b, int* _c) {\n",
        "\tint tID = threadIdx.x;\n",
        "\t_c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "\n",
        "\tint* a, * b, * c, * hc;\t// Vectors on the host\n",
        "\tint* da, * db, * dc;\t// Vectors on the device\n",
        "\n",
        "\tint memSize = sizeof(int) * NUM_DATA;\n",
        "\tprintf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\t// Memory allocation on the host-side\n",
        "\ta = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "\tb = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "\tc = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\thc = new int[NUM_DATA]; memset(hc, 0, memSize);\n",
        "\n",
        "\t// Data generation\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\ta[i] = rand() % 10;\n",
        "\t\tb[i] = rand() % 10;\n",
        "\t}\n",
        "\n",
        "\n",
        "\t// Vector sum on host (for performance comparision)\n",
        "  auto hostStart = std::chrono::high_resolution_clock::now();\n",
        "\tfor (int i = 0; i < NUM_DATA; i++)\n",
        "\t\thc[i] = a[i] + b[i];\n",
        "  auto hostEnd = std::chrono::high_resolution_clock::now();\n",
        "  // 밀리초 단위로 경과 시간 계산 (소수점 포함)\n",
        "  std::chrono::duration<double, std::milli> hostElapsed = hostEnd - hostStart;\n",
        "\n",
        "\n",
        "\t// Memory allocation on the device-side\n",
        "\tcudaMalloc(&da, memSize); cudaMemset(da, 0, memSize);\n",
        "\tcudaMalloc(&db, memSize); cudaMemset(db, 0, memSize);\n",
        "\tcudaMalloc(&dc, memSize); cudaMemset(dc, 0, memSize);\n",
        "\n",
        "  auto GPUstart = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "\t// Data copy : Host -> Device\n",
        "\tauto h2dStart = std::chrono::high_resolution_clock::now();\n",
        "\tcudaMemcpy(da, a, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(db, b, memSize, cudaMemcpyHostToDevice);\n",
        "\tauto h2dEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> h2dElapsed = h2dEnd - h2dStart;\n",
        "\n",
        "\t// Kernel call\n",
        "\tauto kernelStart = std::chrono::high_resolution_clock::now();\n",
        "\tvecAdd <<<1, NUM_DATA >>> (da, db, dc);\n",
        "  auto kernelEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> kernelElapsed = kernelEnd - kernelStart;\n",
        "\n",
        "\n",
        "\t// Copy results : Device -> Host\n",
        "  auto d2hStart = std::chrono::high_resolution_clock::now();\n",
        "\tcudaMemcpy(c, dc, memSize, cudaMemcpyDeviceToHost);\n",
        "  auto d2hEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> d2hElapsed = d2hEnd - d2hStart;\n",
        "\n",
        "\tauto GPUend = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> GPUelapsed = GPUend - GPUstart;\n",
        "\n",
        "\t// Release device memory\n",
        "\tcudaFree(da); cudaFree(db); cudaFree(dc);\n",
        "\n",
        "  // 결과 출력 (밀리초 단위, 소수점 포함)\n",
        "  std::cout << \"Host time: \" << hostElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Host -> Device: \" << h2dElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Kernel: \" << kernelElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Device -> Host: \" << d2hElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"CUDA Total Time: \" << GPUelapsed.count() << \" ms\" << std::endl;\n",
        "\n",
        "\t// Check results\n",
        "\tbool result = true;\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\tif (hc[i] != c[i]) {\n",
        "\t\t\tprintf(\"[%d] The result is not matched! (%d, %d)\\n\"\n",
        "\t\t\t\t, i, hc[i], c[i]);\n",
        "\t\t\tresult = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tif (result)\n",
        "\t\tprintf(\"GPU works well!\\n\");\n",
        "\n",
        "\t// Release host memory\n",
        "\tdelete[] a; delete[] b; delete[] c;\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2zI0e9VE4Hk",
        "outputId": "be952c97-e89a-4696-c806-0b22be3cd4c7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024 elements, memSize = 4096 bytes\n",
            "Host time: 0.002958 ms\n",
            "Host -> Device: 0.022639 ms\n",
            "Kernel: 0.141264 ms\n",
            "Device -> Host: 0.019987 ms\n",
            "CUDA Total Time: 0.184389 ms\n",
            "GPU works well!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**별 차이가 없다 이유를 생각해보자면?**\n",
        "\n",
        "**cudaMemcpy** 때문인 것 같다.\n",
        "\n",
        "cudaMemcpy는 자동으로 동기화로 수행되어서 간단한 연산에서는 굳이 동기화를 명시하지 않아도 동기화로 수행되는 것 같다."
      ],
      "metadata": {
        "id": "rRvexbYxFd1K"
      }
    }
  ]
}