{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPMGTJ8igV/35VmeBBbrBwl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonji0401/CUDA_practice/blob/main/performance_measurements.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **성능 측정 테스트**\n",
        "\n",
        "\n",
        "이전 벡터의 합 성능 측정 당시 사용한 chrono 방식과 cudaEvent 방식으로 비교해서 측정해본 뒤 결과 확인해보기\n",
        "\n",
        "\n",
        "**1. chrono 방식**"
      ],
      "metadata": {
        "id": "6mljiRRG478y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "\n",
        "// The size of the vector\n",
        "#define NUM_DATA 1024\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int* _a, int* _b, int* _c) {\n",
        "\tint tID = threadIdx.x;\n",
        "\t_c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "\n",
        "\tint* a, * b, * c, * hc;\t// Vectors on the host\n",
        "\tint* da, * db, * dc;\t// Vectors on the device\n",
        "\n",
        "\tint memSize = sizeof(int) * NUM_DATA;\n",
        "\tprintf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\t// Memory allocation on the host-side\n",
        "\ta = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "\tb = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "\tc = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\thc = new int[NUM_DATA]; memset(hc, 0, memSize);\n",
        "\n",
        "\t// Data generation\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\ta[i] = rand() % 10;\n",
        "\t\tb[i] = rand() % 10;\n",
        "\t}\n",
        "\n",
        "\n",
        "\t// Vector sum on host (for performance comparision)\n",
        "  auto hostStart = std::chrono::high_resolution_clock::now();\n",
        "\tfor (int i = 0; i < NUM_DATA; i++)\n",
        "\t\thc[i] = a[i] + b[i];\n",
        "  auto hostEnd = std::chrono::high_resolution_clock::now();\n",
        "  // 밀리초 단위로 경과 시간 계산 (소수점 포함)\n",
        "  std::chrono::duration<double, std::milli> hostElapsed = hostEnd - hostStart;\n",
        "\n",
        "\n",
        "\t// Memory allocation on the device-side\n",
        "\tcudaMalloc(&da, memSize); cudaMemset(da, 0, memSize);\n",
        "\tcudaMalloc(&db, memSize); cudaMemset(db, 0, memSize);\n",
        "\tcudaMalloc(&dc, memSize); cudaMemset(dc, 0, memSize);\n",
        "\n",
        "  auto GPUstart = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "\t// Data copy : Host -> Device\n",
        "\tauto h2dStart = std::chrono::high_resolution_clock::now();\n",
        "\tcudaMemcpy(da, a, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(db, b, memSize, cudaMemcpyHostToDevice);\n",
        "\tauto h2dEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> h2dElapsed = h2dEnd - h2dStart;\n",
        "\n",
        "\t// Kernel call\n",
        "\tauto kernelStart = std::chrono::high_resolution_clock::now();\n",
        "\tvecAdd <<<1, NUM_DATA >>> (da, db, dc);\n",
        "\tcudaDeviceSynchronize(); // synchronization function\n",
        "  auto kernelEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> kernelElapsed = kernelEnd - kernelStart;\n",
        "\n",
        "\n",
        "\t// Copy results : Device -> Host\n",
        "  auto d2hStart = std::chrono::high_resolution_clock::now();\n",
        "\tcudaMemcpy(c, dc, memSize, cudaMemcpyDeviceToHost);\n",
        "  auto d2hEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> d2hElapsed = d2hEnd - d2hStart;\n",
        "\n",
        "\tauto GPUend = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> GPUelapsed = GPUend - GPUstart;\n",
        "\n",
        "\t// Release device memory\n",
        "\tcudaFree(da); cudaFree(db); cudaFree(dc);\n",
        "\n",
        "  // 결과 출력 (밀리초 단위, 소수점 포함)\n",
        "  std::cout << \"Host time: \" << hostElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Host -> Device: \" << h2dElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Kernel: \" << kernelElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Device -> Host: \" << d2hElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"CUDA Total Time: \" << GPUelapsed.count() << \" ms\" << std::endl;\n",
        "\n",
        "\t// Check results\n",
        "\tbool result = true;\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\tif (hc[i] != c[i]) {\n",
        "\t\t\tprintf(\"[%d] The result is not matched! (%d, %d)\\n\"\n",
        "\t\t\t\t, i, hc[i], c[i]);\n",
        "\t\t\tresult = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tif (result)\n",
        "\t\tprintf(\"GPU works well!\\n\");\n",
        "\n",
        "\t// Release host memory\n",
        "\tdelete[] a; delete[] b; delete[] c;\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVYcio5F55Rc",
        "outputId": "5786e28b-aca3-4748-b8de-c7d5fd009b33"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024 elements, memSize = 4096 bytes\n",
            "Host time: 0.002938 ms\n",
            "Host -> Device: 0.022235 ms\n",
            "Kernel: 0.152926 ms\n",
            "Device -> Host: 0.016128 ms\n",
            "CUDA Total Time: 0.191843 ms\n",
            "GPU works well!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3번 실행 결과 평균**\n",
        "\n",
        "**Host :** 0.003306 ms\n",
        "\n",
        "**Host -> Device :** 0.072495 ms\n",
        "\n",
        "**Kernel:** 0.10874393 ms\n",
        "\n",
        "**Device -> Host:** 0.0171623 ms\n",
        "\n",
        "**CUDA Total time:** 0.210348 ms\n",
        "\n",
        "**cudaTotal-(h2d+kernel+d2h) = 0.01194677**"
      ],
      "metadata": {
        "id": "9JbjJEq6_xWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. CUDA Event 방식**\n",
        "\n",
        "> CUDA event방식으로는 CPU 성능 측정이 불가함으로 호스트 코드 외 측정"
      ],
      "metadata": {
        "id": "T6QumwvkB3yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "\n",
        "// The size of the vector\n",
        "#define NUM_DATA 1024\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int* _a, int* _b, int* _c) {\n",
        "\tint tID = threadIdx.x;\n",
        "\t_c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "\n",
        "\tint* a, * b, * c, * hc;\t// Vectors on the host\n",
        "\tint* da, * db, * dc;\t// Vectors on the device\n",
        "\n",
        "\tint memSize = sizeof(int) * NUM_DATA;\n",
        "\tprintf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\t// Memory allocation on the host-side\n",
        "\ta = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "\tb = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "\tc = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\thc = new int[NUM_DATA]; memset(hc, 0, memSize);\n",
        "\n",
        "\t// Data generation\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\ta[i] = rand() % 10;\n",
        "\t\tb[i] = rand() % 10;\n",
        "\t}\n",
        "\n",
        "\n",
        "\t// Vector sum on host (for performance comparision)\n",
        "  auto start = std::chrono::high_resolution_clock::now();\n",
        "\tfor (int i = 0; i < NUM_DATA; i++)\n",
        "\t\thc[i] = a[i] + b[i];\n",
        "  auto end = std::chrono::high_resolution_clock::now();\n",
        "  // 밀리초 단위로 경과 시간 계산 (소수점 포함)\n",
        "  std::chrono::duration<double, std::milli> elapsed = end - start;\n",
        "\n",
        "\n",
        "  cudaEvent_t totalStart, totalStop, h2dStart, h2dStop, kernelStart, kernelStop, d2hStart, d2hStop;\n",
        "  cudaEventCreate(&totalStart);\n",
        "  cudaEventCreate(&totalStop);\n",
        "  cudaEventCreate(&h2dStart);\n",
        "  cudaEventCreate(&h2dStop);\n",
        "  cudaEventCreate(&kernelStart);\n",
        "  cudaEventCreate(&kernelStop);\n",
        "  cudaEventCreate(&d2hStart);\n",
        "  cudaEventCreate(&d2hStop);\n",
        "\n",
        "\n",
        "\t// Memory allocation on the device-side\n",
        "\tcudaMalloc(&da, memSize); cudaMemset(da, 0, memSize);\n",
        "\tcudaMalloc(&db, memSize); cudaMemset(db, 0, memSize);\n",
        "\tcudaMalloc(&dc, memSize); cudaMemset(dc, 0, memSize);\n",
        "\n",
        "  cudaEventRecord(totalStart, 0);\n",
        "\n",
        "\t// Data copy : Host -> Device\n",
        "\tcudaEventRecord(h2dStart, 0);\n",
        "\tcudaMemcpy(da, a, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(db, b, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaEventRecord(h2dStop, 0);\n",
        "  cudaEventSynchronize(h2dStop);\n",
        "  float h2dTime;\n",
        "  cudaEventElapsedTime(&h2dTime, h2dStart, h2dStop);\n",
        "\n",
        "\t// Kernel call\n",
        "\tcudaEventRecord(kernelStart, 0);\n",
        "\tvecAdd <<<1, NUM_DATA >>> (da, db, dc);\n",
        "  cudaEventRecord(kernelStop, 0);\n",
        "  cudaEventSynchronize(kernelStop);\n",
        "  float kernelTime;\n",
        "  cudaEventElapsedTime(&kernelTime, kernelStart, kernelStop);\n",
        "\n",
        "\t// Copy results : Device -> Host\n",
        "  cudaEventRecord(d2hStart, 0);\n",
        "\tcudaMemcpy(c, dc, memSize, cudaMemcpyDeviceToHost);\n",
        "  cudaEventRecord(d2hStop, 0);\n",
        "  cudaEventSynchronize(d2hStop);\n",
        "  float d2hTime;\n",
        "  cudaEventElapsedTime(&d2hTime, d2hStart, d2hStop);\n",
        "\n",
        "\tcudaEventRecord(totalStop, 0);\n",
        "  cudaEventSynchronize(totalStop);\n",
        "  float totalTime;\n",
        "  cudaEventElapsedTime(&totalTime, totalStart, totalStop);\n",
        "\n",
        "\t// Release device memory\n",
        "\tcudaFree(da); cudaFree(db); cudaFree(dc);\n",
        "\n",
        "  // 결과 출력 (밀리초 단위, 소수점 포함)\n",
        "  std::cout << \"Host time: \" << elapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Host -> Device: \" << h2dTime << \" ms\" << std::endl;\n",
        "  std::cout<<\"Kernel: \" << kernelTime << \" ms\" << std::endl;\n",
        "  std::cout<<\"Device -> Host: \" << d2hTime << \" ms\" << std::endl;\n",
        "  std::cout<<\"CUDA Total Time: \" << totalTime << \" ms\" << std::endl;\n",
        "\n",
        "  cudaEventDestroy(totalStart);\n",
        "  cudaEventDestroy(totalStop);\n",
        "  cudaEventDestroy(h2dStart);\n",
        "  cudaEventDestroy(h2dStop);\n",
        "  cudaEventDestroy(kernelStart);\n",
        "  cudaEventDestroy(kernelStop);\n",
        "  cudaEventDestroy(d2hStart);\n",
        "  cudaEventDestroy(d2hStop);\n",
        "\n",
        "\t// Check results\n",
        "\tbool result = true;\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\tif (hc[i] != c[i]) {\n",
        "\t\t\tprintf(\"[%d] The result is not matched! (%d, %d)\\n\"\n",
        "\t\t\t\t, i, hc[i], c[i]);\n",
        "\t\t\tresult = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tif (result)\n",
        "\t\tprintf(\"GPU works well!\\n\");\n",
        "\n",
        "\t// Release host memory\n",
        "\tdelete[] a; delete[] b; delete[] c;\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMLl_u9VCYNJ",
        "outputId": "a39e5fc9-4074-44dc-f8ba-46cac6727b74"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024 elements, memSize = 4096 bytes\n",
            "Host time: 0.002987 ms\n",
            "Host -> Device: 0.034208 ms\n",
            "Kernel: 0.191776 ms\n",
            "Device -> Host: 0.01856 ms\n",
            "CUDA Total Time: 0.273536 ms\n",
            "GPU works well!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3번 실행 결과 평균**\n",
        "\n",
        "**Host -> Device :** 0.0260293 ms\n",
        "\n",
        "**Kernel:** 0.1693626667 ms\n",
        "\n",
        "**Device -> Host:** 0.01904 ms\n",
        "\n",
        "**CUDA Total time:** 0.2434773 ms\n",
        "\n",
        "**cudaTotal-(h2d+kernel+d2h) = 0.0290453**"
      ],
      "metadata": {
        "id": "l_0ihE0lCzmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**주의할 점!**\n",
        "\n",
        "> 호스트, 디바이스 간의 데이터 복사는 호스트 코드를 포함하고 있어 CUDA EVENT로는 CPU의 오버헤드가 측정되지 않는다. GPU가 데이터 전송을 시작하고 완료할 때까지의 시간만을 측정하게 된다. 그래서 결과에서 데이터 복사 시간의 평균이 chrono에서 수행할때가 더 긴 것 같다.\n",
        "\n",
        "\n",
        "**결론**\n",
        "> 연산이 단순해서 결과가 큰 차이가 나지는 않는다.\n",
        "\n",
        "> 그러나 다시 시간측정을 해보며 조사해본 결과 *cudaEvent는* GPU내에서만 수행되는 코드 시간을 측정하기에 더 적합하고 cpu와 gpu를 둘 다 측정해야한다면 chrono나 QPC방법이 더 적합하다.\n"
      ],
      "metadata": {
        "id": "gF7ucgADN--L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**가장 좋은 측정 방식!**\n",
        "\n",
        "커널 코드 부분만 cudaEvent로 측정한다!"
      ],
      "metadata": {
        "id": "SE9QBIV3PkbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "\n",
        "// The size of the vector\n",
        "#define NUM_DATA 1024\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int* _a, int* _b, int* _c) {\n",
        "\tint tID = threadIdx.x;\n",
        "\t_c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "\n",
        "\tint* a, * b, * c, * hc;\t// Vectors on the host\n",
        "\tint* da, * db, * dc;\t// Vectors on the device\n",
        "\n",
        "\tint memSize = sizeof(int) * NUM_DATA;\n",
        "\tprintf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\t// Memory allocation on the host-side\n",
        "\ta = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "\tb = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "\tc = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\thc = new int[NUM_DATA]; memset(hc, 0, memSize);\n",
        "\n",
        "\t// Data generation\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\ta[i] = rand() % 10;\n",
        "\t\tb[i] = rand() % 10;\n",
        "\t}\n",
        "\n",
        "\n",
        "\t// Vector sum on host (for performance comparision)\n",
        "  auto hostStart = std::chrono::high_resolution_clock::now();\n",
        "\tfor (int i = 0; i < NUM_DATA; i++)\n",
        "\t\thc[i] = a[i] + b[i];\n",
        "  auto hostEnd = std::chrono::high_resolution_clock::now();\n",
        "  // 밀리초 단위로 경과 시간 계산 (소수점 포함)\n",
        "  std::chrono::duration<double, std::milli> hostElapsed = hostEnd - hostStart;\n",
        "\n",
        "\n",
        "\t// Memory allocation on the device-side\n",
        "\tcudaMalloc(&da, memSize); cudaMemset(da, 0, memSize);\n",
        "\tcudaMalloc(&db, memSize); cudaMemset(db, 0, memSize);\n",
        "\tcudaMalloc(&dc, memSize); cudaMemset(dc, 0, memSize);\n",
        "\n",
        "  cudaEvent_t kernelStart, kernelStop;\n",
        "  cudaEventCreate(&kernelStart);\n",
        "  cudaEventCreate(&kernelStop);\n",
        "\n",
        "  auto GPUstart = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "\t// Data copy : Host -> Device\n",
        "\tauto h2dStart = std::chrono::high_resolution_clock::now();\n",
        "\tcudaMemcpy(da, a, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(db, b, memSize, cudaMemcpyHostToDevice);\n",
        "\tauto h2dEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> h2dElapsed = h2dEnd - h2dStart;\n",
        "\n",
        "\t// Kernel call\n",
        "\tcudaEventRecord(kernelStart, 0);\n",
        "\tvecAdd <<<1, NUM_DATA >>> (da, db, dc);\n",
        "  cudaEventRecord(kernelStop, 0);\n",
        "  cudaEventSynchronize(kernelStop);\n",
        "  float kernelTime;\n",
        "  cudaEventElapsedTime(&kernelTime, kernelStart, kernelStop);\n",
        "\n",
        "\n",
        "\t// Copy results : Device -> Host\n",
        "  auto d2hStart = std::chrono::high_resolution_clock::now();\n",
        "\tcudaMemcpy(c, dc, memSize, cudaMemcpyDeviceToHost);\n",
        "  auto d2hEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> d2hElapsed = d2hEnd - d2hStart;\n",
        "\n",
        "\tauto GPUend = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> GPUelapsed = GPUend - GPUstart;\n",
        "\n",
        "\t// Release device memory\n",
        "\tcudaFree(da); cudaFree(db); cudaFree(dc);\n",
        "\n",
        "  // 결과 출력 (밀리초 단위, 소수점 포함)\n",
        "  std::cout << \"Host time: \" << hostElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Host -> Device: \" << h2dElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Kernel: \" << kernelTime << \" ms\" << std::endl;\n",
        "  std::cout<<\"Device -> Host: \" << d2hElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"CUDA Total Time: \" << GPUelapsed.count() << \" ms\" << std::endl;\n",
        "\n",
        "  cudaEventDestroy(kernelStart);\n",
        "  cudaEventDestroy(kernelStop);\n",
        "\n",
        "\t// Check results\n",
        "\tbool result = true;\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\tif (hc[i] != c[i]) {\n",
        "\t\t\tprintf(\"[%d] The result is not matched! (%d, %d)\\n\"\n",
        "\t\t\t\t, i, hc[i], c[i]);\n",
        "\t\t\tresult = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tif (result)\n",
        "\t\tprintf(\"GPU works well!\\n\");\n",
        "\n",
        "\t// Release host memory\n",
        "\tdelete[] a; delete[] b; delete[] c;\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGhlvlMKPrGz",
        "outputId": "8aac6eb9-e097-4d2a-bf8e-39085a3a57b5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024 elements, memSize = 4096 bytes\n",
            "Host time: 0.002973 ms\n",
            "Host -> Device: 0.025917 ms\n",
            "Kernel: 0.163424 ms\n",
            "Device -> Host: 0.017369 ms\n",
            "CUDA Total Time: 0.220841 ms\n",
            "GPU works well!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3번 실행 결과 평균**\n",
        "\n",
        "**Host -> Device :** 0.0236973 ms\n",
        "\n",
        "**Kernel:** 0.1594346667 ms\n",
        "\n",
        "**Device -> Host:** 0.016929 ms\n",
        "\n",
        "**CUDA Total time:** 0.214474 ms\n",
        "\n",
        "**cudaTotal-(h2d+kernel+d2h) = 0.01441303**"
      ],
      "metadata": {
        "id": "y7GGD1aERDp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **결과 비교**\n",
        "\n",
        "cudaTotal 시간은 디바이스 코드 실행 시간으로 데이터 복사 시간 포함 커널 실행 시간을 포함하고 있다.\n",
        "\n",
        "정확도 측정을 위해서 cudaTotal시간에서 데이터 복사 시간과 커널 실행 시간의 차를 구해 비교해보았다.\n",
        "\n",
        "1. chrono로만 측정했을 때 : 0.01194677 ms\n",
        "2. cudaEvent로만 측정했을 떄: 0.0290453 ms\n",
        "3. 둘 다 사용했을 떄 : 0.01441303 ms\n",
        "\n",
        "cudaEvent 시간이 제일 많이 차이가 나는 것으로 보아 아무래도 데이터 복사 시간에서의 차이로 인한 것으로 추측된다.\n",
        "\n",
        "cudaEvent는 CPU내 데이터 복사 시간은 포함하지 않기 때문이다.\n",
        "\n",
        "(API 호출 시간은 감안하지 않은 결과이다.)"
      ],
      "metadata": {
        "id": "FG5h9-yJTWZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**추가: 만약 chrono 방식에서 동기화가 이루어지지 않는다면?**"
      ],
      "metadata": {
        "id": "O_wbz8zbEMsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "\n",
        "// The size of the vector\n",
        "#define NUM_DATA 1024\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int* _a, int* _b, int* _c) {\n",
        "\tint tID = threadIdx.x;\n",
        "\t_c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "\n",
        "\tint* a, * b, * c, * hc;\t// Vectors on the host\n",
        "\tint* da, * db, * dc;\t// Vectors on the device\n",
        "\n",
        "\tint memSize = sizeof(int) * NUM_DATA;\n",
        "\tprintf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\t// Memory allocation on the host-side\n",
        "\ta = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "\tb = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "\tc = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\thc = new int[NUM_DATA]; memset(hc, 0, memSize);\n",
        "\n",
        "\t// Data generation\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\ta[i] = rand() % 10;\n",
        "\t\tb[i] = rand() % 10;\n",
        "\t}\n",
        "\n",
        "\n",
        "\t// Vector sum on host (for performance comparision)\n",
        "  auto hostStart = std::chrono::high_resolution_clock::now();\n",
        "\tfor (int i = 0; i < NUM_DATA; i++)\n",
        "\t\thc[i] = a[i] + b[i];\n",
        "  auto hostEnd = std::chrono::high_resolution_clock::now();\n",
        "  // 밀리초 단위로 경과 시간 계산 (소수점 포함)\n",
        "  std::chrono::duration<double, std::milli> hostElapsed = hostEnd - hostStart;\n",
        "\n",
        "\n",
        "\t// Memory allocation on the device-side\n",
        "\tcudaMalloc(&da, memSize); cudaMemset(da, 0, memSize);\n",
        "\tcudaMalloc(&db, memSize); cudaMemset(db, 0, memSize);\n",
        "\tcudaMalloc(&dc, memSize); cudaMemset(dc, 0, memSize);\n",
        "\n",
        "  auto GPUstart = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "\t// Data copy : Host -> Device\n",
        "\tauto h2dStart = std::chrono::high_resolution_clock::now();\n",
        "\tcudaMemcpy(da, a, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(db, b, memSize, cudaMemcpyHostToDevice);\n",
        "\tauto h2dEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> h2dElapsed = h2dEnd - h2dStart;\n",
        "\n",
        "\t// Kernel call\n",
        "\tauto kernelStart = std::chrono::high_resolution_clock::now();\n",
        "\tvecAdd <<<1, NUM_DATA >>> (da, db, dc);\n",
        "  auto kernelEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> kernelElapsed = kernelEnd - kernelStart;\n",
        "\n",
        "\n",
        "\t// Copy results : Device -> Host\n",
        "  auto d2hStart = std::chrono::high_resolution_clock::now();\n",
        "\tcudaMemcpy(c, dc, memSize, cudaMemcpyDeviceToHost);\n",
        "  auto d2hEnd = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> d2hElapsed = d2hEnd - d2hStart;\n",
        "\n",
        "\tauto GPUend = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double, std::milli> GPUelapsed = GPUend - GPUstart;\n",
        "\n",
        "\t// Release device memory\n",
        "\tcudaFree(da); cudaFree(db); cudaFree(dc);\n",
        "\n",
        "  // 결과 출력 (밀리초 단위, 소수점 포함)\n",
        "  std::cout << \"Host time: \" << hostElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Host -> Device: \" << h2dElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Kernel: \" << kernelElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"Device -> Host: \" << d2hElapsed.count() << \" ms\" << std::endl;\n",
        "  std::cout<<\"CUDA Total Time: \" << GPUelapsed.count() << \" ms\" << std::endl;\n",
        "\n",
        "\t// Check results\n",
        "\tbool result = true;\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\tif (hc[i] != c[i]) {\n",
        "\t\t\tprintf(\"[%d] The result is not matched! (%d, %d)\\n\"\n",
        "\t\t\t\t, i, hc[i], c[i]);\n",
        "\t\t\tresult = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tif (result)\n",
        "\t\tprintf(\"GPU works well!\\n\");\n",
        "\n",
        "\t// Release host memory\n",
        "\tdelete[] a; delete[] b; delete[] c;\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2zI0e9VE4Hk",
        "outputId": "be952c97-e89a-4696-c806-0b22be3cd4c7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024 elements, memSize = 4096 bytes\n",
            "Host time: 0.002958 ms\n",
            "Host -> Device: 0.022639 ms\n",
            "Kernel: 0.141264 ms\n",
            "Device -> Host: 0.019987 ms\n",
            "CUDA Total Time: 0.184389 ms\n",
            "GPU works well!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**별 차이가 없다 이유를 생각해보자면?**\n",
        "\n",
        "**cudaMemcpy** 때문인 것 같다.\n",
        "\n",
        "cudaMemcpy는 자동으로 동기화로 수행되어서 간단한 연산에서는 굳이 동기화를 명시하지 않아도 동기화로 수행되는 것 같다."
      ],
      "metadata": {
        "id": "rRvexbYxFd1K"
      }
    }
  ]
}