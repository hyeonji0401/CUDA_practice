{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6IbkpWM/tDjyCoQKnY6+s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonji0401/CUDA_practice/blob/main/CUDA_memory_hierarchy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.1 컴퓨터 시스템의 메모리 계층\n",
        "\n",
        "보조기억장치 -> 메인 메모리 -> 캐시 -> 레지스터\n",
        "\n",
        "-> 으로 갈수록 적은 용량, 고성능, 고가임\n",
        "\n",
        "- 보조기억장치(auxilary memory)\n",
        " - 흔히 디스크로 부르며 데이터를 보관하기 위해 사용함\n",
        " - 컴퓨터가 데이터를 사용하기 위해서는 보조기억장치에 있는 데이터를 메인 메모리로 가지고 와야함\n",
        "- 메인 메모리(main memory)\n",
        " - 연산 장치가 접근할 수 있는 가장 먼 저장장치로 연산을 위한 데이터를 보관하는 공간\n",
        " - 흔히 메모리라고 부름\n",
        "\n",
        "**=> 보조메모리와 메인 메모리를 구분한 이유**\n",
        "\n",
        "- 최소한의 비용으로 최대한의 효과를 얻기 위해\n",
        " - 저렴하지만 용량이 큰 보조기억장치에 모든 데이터를 보관해두고 현재 작업에 필요한 데이터만 속도가 빠른 메인 메모리에 가져와 사용하는 방법으로 용량과 속도를 둘다 잡는 전략\n",
        "\n",
        " - 레지스터 & 캐시\n",
        "  - CPU 내부에 있는 메모리롤 메인 메모리보다 월등히 빠르지만 그만큼 비싸고 매우 작은 저장공간\n",
        "  - 레지스터 : 연산 장치가 현재 수행 중인 연산을 위해 사용하는 임시 저장 공간\n",
        "  - 캐시 : 자주 사용하는 데이터를 가져다 놓는 공간\n",
        "  - 우리가 직접 제어할 수 없고 CPU와 같은 하드웨어에 의해 관리됨\n",
        "\n",
        "\n",
        "=> GPU 메모리도 계층을 나눠놓은 이유가 유사하지만 CPU의 캐시와 달리 GPU는 특정 캐시 메모리(공유 메모리)를 직접 제어할 수 있는 특성을 가짐"
      ],
      "metadata": {
        "id": "339-8TAkMTyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.2 CUDA 메모리 계층\n",
        "\n",
        "1.스레드 수준 메모리\n",
        "- 각 스레드 내부에서 사용되므로 다른 스레드에서 접근할 수 없는 메모리 공간\n",
        "\n",
        "가. 레지스터\n",
        "- CUDA 코어 연산을 위한 데이터를 담아두고 사용하는 공간\n",
        "- 스레드가 연산을 위해 데이터를 저장하는 공간\n",
        "- 커널 내부에서 선언된 지역 변수를 위해 사용됨\n",
        "- GPU 메모리 중 가장 빠른 메모리로 일반적으로 GPU cycle보다 작은 시간 소요\n",
        "- SM내부에 있어 인-코어(in-core) 메모리라고 부름\n",
        "- 속도는 빠르지만 가장 크기가 작은 메모리임(블록 또는 SM하나당 8k-64k개의 32비트)\n",
        "\n",
        " ex) 하나의 스레드 블록 당 최대 스레드 1024개를 사용하는 경우\n",
        "\n",
        "    - 한 스레드는 8 ~ 64개의 레지스터만 사용 가능 (8 ~ 64개의 정수형 변수,,)\n",
        "- 활성 블록 수를 늘리게 되면 스레드 당 사용가능한 레지스터 수는 더 줄어들음\n",
        "\n",
        "=> 활성 블록의 수를 2로 만들면 스레드당 할당 가능한 레지스터 수는 절반으로 줄어듦\n",
        "\n",
        "- 실제 지역 변수의 수가 사용 가능한 레지스터 수보다 많은 경우, 어떤 지역 변수를 레지스터에 담을지 여부는 컴파일러에 의해 결정됨\n",
        "- 레지스터 담지 못하는 지역 변수는 지역 메모리에 할당됨\n",
        "\n",
        "2. 지역 메모리\n",
        "- SM 밖에 있는 오프-칩(off-chip) 메모리임\n",
        "- 접근 속도는 400 ~ 600 GPU cycle정도로 레지스터보다 느리지만 사용 가능한 메모리 공간이 큼\n",
        "- GPU 디바이스 메모리(DRAM: GPU사양에서 말하는 '메모리'를 의미함) 공간 일부가 지역 메모리로 사용됨\n",
        "- 전역 메모리 또한 디바이스 메모리 영역을 사용하지만 지역 메모리는 각 스레드가 자신만의 공간을 갖는다는 점에서 전역메모리와 구분됨\n",
        "- 레지스터를 사용하기에는 큰 구조체나 배열 등이나 일반 변수이지만 레지스터 공간을 할당 받지 못할 경우 지역 메모리 공간을 사용함\n",
        "(스레드당 512KB 제한이 있지만 스레드 하나가 지역 변수를 사용하기에는 충분함)\n",
        "\n"
      ],
      "metadata": {
        "id": "rEny6a0zTJlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.블록 수준 메모리\n",
        "- 모든 스레드가 접근할 수 있는 공유 메모리 공간\n",
        "- 1~4 GPU cycle 정도로 속도가 빠른 온-칩 메모리임\n",
        "- 디바이스 메모리보다 작으며 compute capability에 따라 SM당 16~96kb의 크기를 가짐\n",
        "- 공유 메모리 공간을 어떻게 사용하느냐에 따라 CUDA 프로그램 성능이 수 배 빨라질 수 있음 따라서 해당 메모리 공간의 크기를 아는 것이 중요함\n",
        "- 블록 내 모든 스레드가 공동으로 자주 사용하는 데이터를 보관함으로써 메모리 공간을 절약함과 동시에 데이터 접근 속도를 높일 수 있음\n",
        "- SM 내 공유 메모리 공간은 해당 SM을 사용하는 스레드 블록들이 나누어서 사용하므로 하나의 스레드 블록에서 사용하는 공유 메모리 공간의 크기는 활성 블록의 수에 영향을 줌\n",
        "- 공유 메모리를 사용하는 방법은 크게 3가지로 9장에서 나올 예정\n",
        " - 사용자가 직접 관리하는 사용자 관리 캐시 형태 사용법\n",
        "   - 공유 메모리를 __shared__지시어를 통해 명시적으로 선언 및 할당\n",
        "   - 정적할당과 동적할당 방법으로 할당받을 수 있음\n",
        "\n",
        "가. 정적 할당(static allocation)\n",
        "\n",
        "\n",
        "```\n",
        "__global__ void kernel(void)\n",
        "{\n",
        "  __shared__ int sharedMemory[512];\n",
        "}\n",
        "```\n",
        "- 커널 내부에서 공유 메모리 공간을 선언 및 할당하는 방법\n",
        "- '__ shared __'가 붙은 변수 선언의 경우 각 스레드의 지역변수가 아닌 스레드 블록 내 모든 스레드가 공유하는 변수로 선언됨\n",
        "- 해당 변수는 스레드 블록당 하나만 선언된다는 의미임(서로 다른 스레드 블록은 자신만의 sharedMemory배열을 가진다는 말임)\n",
        "- 정적 할당의 경우 CUDA 프로그램이 컴파일될때 크기가 결정됨\n",
        "- compute capability와 같은 GPU 사양에 따라 사용할 공유 메모리의 크기를 변경하고 싶으면 동적 할당 방법을 사용하면됨\n",
        "\n",
        "나. 동적 할당(dynamic allocation)\n",
        "\n",
        "\n",
        "```\n",
        "extern __shared__ int sharedMemory[];\n",
        "__global__ void kernel(void)\n",
        "{...}\n",
        "int main(void)\n",
        "{\n",
        "  int size = 512;\n",
        "  kernel<<<gridDim, blockDim, sizeof(int) * size>>>();\n",
        "}\n",
        "```\n",
        "- 크기가 정해지지 않은 extern 배열 형태(빈 대괄호 사용)로 커널 밖에서 선언\n",
        "- 배열의 크기는 실행 구성의 세번째 인자 값에 의해 결정되어 커널 실행 시 메모리 공간이 할당됨\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "extern __shared__ int sharedPool[];\n",
        "int *sIntArray = sharedPool;\n",
        "float *sFloatArray = (float*)&sharedPool[sizeIntArr];\n",
        "\n",
        "__global__ void kernel(void){\n",
        "  ...\n",
        "  sIntArray[threadIdx.x]=0;\n",
        "  sFloatArray[thtreadIdx.x] = 0.0f;\n",
        "  ...\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  int size=512;\n",
        "  kernel <<gridDim, blockDim, sizeof(int) * sizeIntArr + sizeif(float) * sizeFloatArr>>>();\n",
        "}\n",
        "```\n",
        "- 실행 구성의 세 번째 인자에는 하나의 값만 전달 가능하며, 여러 개의 공유 메모리 공간을 동적 할당할 수 없다는 의미도 됨\n",
        "- 하나의 커널 안에서 여러 개의 큰 공유 메모리 배열이 필요하다면 모든 배열의 크기를 더한 만큼의 공간을 가지는 하나의 큰 공유 메모리 배열을 선언하고 포인터를 이용하여 해당 공간을 분할하는 방법을 사용해야함\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fsf4gRpkrd16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.그리드 수준 메모리\n",
        "\n",
        "- 그리드 내 모든 스레드가 접근할 수 있는 메모리 영역\n",
        "- 커널을 수행하면 그리드가 생성되므로 커널을 수행하는 모든 스레드가 접근 가능\n",
        "\n",
        "가. 전역 메모리\n",
        "- 모든 스레드가 접근 가능한 메모리 영역이며 디바이스 메모리 공간 사용(전역 메모리를 대략 디바이스 메모리라고도 말함)\n",
        "- GPU 메모리 중 가장 큰 메모리 공간을 차지하지만 접근 속도는 400~800GPU cycle 정도로 가장 느림\n",
        "- CUDA 프로그램을 위한 데이터는 기본적으로 전역 메모리 공간에 적재되며 필요에 따라 공유 메모리나 지역 메모리로 복사되어 사용됨\n",
        "- 호스트 코드에서 cudaMalloc()을 통해 요청한 메모리 공간이 할당되는 공간이 전역 메모리 공간\n",
        "- cudaMemcpy()를 통해 데이터를 복사하는 것은 전역 메모리에 있는 데이터를 복사한다는 의미임\n",
        "\n",
        "=> 전역 메모리는 호스트 디바이스 간 통신 메모리임"
      ],
      "metadata": {
        "id": "ThFQwTwksDfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "나. 상수 메모리\n",
        "\n",
        "\n",
        "```\n",
        "__constant__ int constMemory[512];\n",
        "\n",
        "__global__ void kernel(void){\n",
        "...\n",
        "int a = constMemory[threadIdx.x];\n",
        "constMemory[threadIdx.x]=0;\n",
        "...\n",
        "}\n",
        "int main(void)\n",
        "{\n",
        "  int table[512] = {0};\n",
        "  cudaMemcpyToSymbol(constMemory, table, sizeof(int) * 512); // 상수 메모리 배열 값 초기화\n",
        "  ...\n",
        "  kerenl<<<gridDim, blockDim>>>();\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "- 변하지 않은 값을 저장하고 있는 공간을 의미\n",
        "- 쓰기 연산은 불가능한 읽기 전용 메모리임\n",
        "- 전역 메모리와 동일하게 디바이스 메모리 영역을 사용하며 최대 크기는 64kb임\n",
        "- 전역 메모리와는 달리 전용 온-칩 메모리인 상수 캐시를 사용함\n",
        " - 상수 캐시 크기는 compute capability에 따라 다르며 대략 48kb수준임\n",
        " - 상수 메모리에 대한 접그은 캐싱되며 캐싱 적중률이 높을 경우 전역 메모리 대비 데이터 접근 속도를 크게 높일 수 있음\n",
        "- __ constant __ 키워드를 통해 전역 범위로 선언하며 그 값은 호스트에 의해 커널 호출 전에 초기화되어야함\n",
        "\n",
        "- cudaMemcpyToSymbol 함수 원형( 상수 메모리 변수 값을 초기화하는 함수)\n",
        "\n",
        "\n",
        "```\n",
        "_cudaError_t cudaMemoryToSymbol (const void* symbol, const void* src, size_t count, size_t offset=0, cudaMemcpyKind kind = cudaMemcpyHostToDevice)\n",
        "```\n",
        "- 커널 내부에서 배열의 값을 이용해서 사용할 수는 있으나 배열의 값을 수정할 수는 없음\n",
        "\n"
      ],
      "metadata": {
        "id": "RGFRrZl3jM45"
      }
    }
  ]
}