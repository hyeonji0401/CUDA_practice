{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqBrqjOkjMRu5tKXZqhUiW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonji0401/CUDA_practice/blob/main/helloCUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cuda 버전 확인**"
      ],
      "metadata": {
        "id": "1nXIqkgxcLnd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eF5m4q_YleE",
        "outputId": "32c59ad0-263f-4724-e141-cf67f420b7a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**플러그인 설치**"
      ],
      "metadata": {
        "id": "zbCnHs90cU_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsENnd55cYLF",
        "outputId": "d933c255-375a-4b26-bcaf-6cc4885c3221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-mmv_xcle\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-mmv_xcle\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 801584cceb559adc54e828ebe9b385c5f53fe70f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NVCC 플러그인 설치**"
      ],
      "metadata": {
        "id": "HdkRETXwccLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VJhh29zcfmV",
        "outputId": "22884ec7-56a6-4880-d72e-be9c11c8e029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**코드 작성**"
      ],
      "metadata": {
        "id": "dTQOQ4iBcl4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void helloCUDA(void)\n",
        "{\n",
        "    printf(\"Hello CUDA from GPU!\\n\");\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "    printf(\"hello GPU from CPU\\n\");\n",
        "    helloCUDA<<<1,10>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxgTpwqUdGpn",
        "outputId": "50804316-5206-4d20-9541-b3621cc73e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello GPU from CPU\n",
            "Hello CUDA from GPU!\n",
            "Hello CUDA from GPU!\n",
            "Hello CUDA from GPU!\n",
            "Hello CUDA from GPU!\n",
            "Hello CUDA from GPU!\n",
            "Hello CUDA from GPU!\n",
            "Hello CUDA from GPU!\n",
            "Hello CUDA from GPU!\n",
            "Hello CUDA from GPU!\n",
            "Hello CUDA from GPU!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 코드 설명\n",
        "\n",
        "__global__ : host에서 호출, device에서 실행\n",
        "(커널 함수)\n",
        "\n",
        "__host__ : host에서 호출, host에서 실행 (호스트함수)\n",
        "\n",
        "__device__ : device에서 호출, device에서 실행 (디바이스 함수)\n",
        "\n",
        "\n",
        "* 호스트함수는 호스트코드에서만 디바이스함수는 디바이스코드에서만 호출 가능함"
      ],
      "metadata": {
        "id": "iXiZtVS3eGfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HOST & DEVICE\n",
        "\n",
        "HOST 코드: CPU에서 실행되는 코드\n",
        "\n",
        "DEVICE 코드 : GPU에서 실행되는 코드\n",
        "\n",
        "기본적으로 호스트에서 실행되지만 GPU연산을 수행하기 위해서는 디바이스 코드를 작성해야함\n",
        "\n",
        "-> 그러나 디바이스 함수는 디바이스 코드에서만 호출 가능함\n",
        "\n",
        "=> 그래서 __global__ 키워드를 사용함\n",
        "\n",
        "=> 호스트에서 호출하고 디바이스에서 실행됨\n",
        "\n",
        "**=> CUDA에서는 이를 커널이라고 함**"
      ],
      "metadata": {
        "id": "VCMD9adsjHY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 커널\n",
        "호스트가 디바이스에세 연산을 요청하는 통로\n",
        "\n",
        "CUDA 스레드들의 동작을 정의하는 함수\n",
        "\n",
        "-> 커널 호출 시에는 몇개의 스레드가 연산을 수행할 것인지 여부를 지정해주어야함\n",
        "\n",
        "-> \" <<<>>> \" 실행구성 문법을 통해 지정함\n",
        "\n",
        "CUDA스레드는 특정 단위로 그룹을 이루며 계층적으로 구성되어있음\n",
        "\n",
        "**즉, helloCUDA<<<1,10>>>(); 의 의미는 10개의 CUDA스레드가 helloCUDA커널을 수행하라는 의미임**\n",
        "\n",
        "**cudaDeviceSynchronize();**\n",
        "\n",
        "-> GPU는 비동기로 동작하기 때문에 CPU가 동시에 작업을 수행할 수 있음\n",
        "\n",
        "-> 따라서 CPU가 GPU의 비동기 작업의 동기화를 위해 GPU작업이 완료될 때까지 기다려야함"
      ],
      "metadata": {
        "id": "1mHh5nY2jXp9"
      }
    }
  ]
}