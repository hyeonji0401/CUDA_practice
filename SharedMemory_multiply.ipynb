{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMV2B5EJnnz5gZQCaEX36Ao",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonji0401/CUDA_practice/blob/main/SharedMemory_multiply.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. 공유 메모리를 활용한 행렬 곱셈 프로그램\n",
        "\n",
        "# 10.1 문제 정의 및 기반 코드\n",
        "- 1. GPU에게 공유 메모리 활용을 맡기기\n",
        "  - 하드웨어가 관리하는 L1 캐시로 공유 메모리를 사용\n",
        "  - 데이터 접근 패턴에 기반을 둔 사용자 관리 캐시로 사용하는 방법만큼의 성능 향상은 안됨\n",
        "- 2. 전체 데이터가 아닌 일부 데이터만 올려가면 사용\n",
        "  - 어떤 데이터를 어떤 시점에 공유 메모리에 올리고 내릴지를 사용자가 결정\n",
        "\n",
        "- 문제 정의\n",
        "  - 1,024 이상 크기의 행렬 곱셈을 다룸\n",
        "  - 공유 메모리보다 크기가 커지므로 공유 메모리에 행렬 전체를 올릴 수 없음"
      ],
      "metadata": {
        "id": "lBV5eon-FjI-"
      }
    }
  ]
}